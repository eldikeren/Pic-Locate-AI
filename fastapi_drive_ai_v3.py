from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List
import time
import asyncio
import os
import uuid
import openai
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from PIL import Image, ImageDraw, ImageFont
import io
import torch
import cv2
import numpy as np
from collections import Counter
import ssl
import urllib3
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Configure SSL to handle Google Drive SSL issues
ssl_context = ssl.create_default_context()
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE

# Disable SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# YOLOv8: ultralytics
from ultralytics import YOLO

# CLIP via transformers
from transformers import CLIPProcessor, CLIPModel

# PDF generation
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Image as RLImage, Spacer, Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_RIGHT
from reportlab.lib.units import inch
from docx import Document
from pptx import Presentation
from pptx.util import Inches

# Room type detection (prioritize locations over people)
ROOM_KEYWORDS = {
    'kitchen': ['kitchen', 'stove', 'oven', 'refrigerator', 'sink', 'cabinet', 'counter', 'microwave', 'dishwasher', '◊û◊ò◊ë◊ó', '◊õ◊ô◊®◊ô◊ô◊ù', '◊™◊†◊ï◊®', '◊õ◊ô◊ï◊®'],
    'bedroom': ['bed', 'bedroom', 'mattress', 'pillow', 'nightstand', 'dresser', 'wardrobe', 'closet', '◊ó◊ì◊® ◊©◊ô◊†◊î', '◊û◊ô◊ò◊î'],
    'living room': ['sofa', 'couch', 'tv', 'television', 'coffee table', 'living room', 'lounge', 'armchair', '◊°◊ú◊ï◊ü', '◊°◊§◊î'],
    'bathroom': ['bathroom', 'toilet', 'sink', 'shower', 'bathtub', 'mirror', 'towel', '◊©◊ô◊®◊ï◊™◊ô◊ù', '◊ê◊û◊ë◊ò◊ô◊î'],
    'dining room': ['dining table', 'chair', 'dining room', 'table', 'dining', '◊§◊ô◊†◊™ ◊ê◊ï◊õ◊ú', '◊ó◊ì◊® ◊ê◊ï◊õ◊ú', '◊©◊ï◊ú◊ó◊ü'],
    'office': ['desk', 'computer', 'office', 'chair', 'monitor', 'keyboard', 'laptop', '◊û◊©◊®◊ì', '◊ó◊ì◊® ◊¢◊ë◊ï◊ì◊î'],
    'nursery': ['nursery', 'baby', 'child', 'kids', 'crib', 'toy', '◊ó◊ì◊® ◊ô◊ú◊ì◊ô◊ù', '◊ó◊ì◊® ◊™◊ô◊†◊ï◊ß'],
    'garden': ['garden', 'plant', 'tree', 'flower', 'outdoor', 'patio', 'lawn', '◊í◊ü', '◊í◊ô◊†◊î'],
    'garage': ['garage', 'car', 'vehicle', 'tool', 'workshop', '◊ó◊†◊ô◊î', '◊û◊ï◊°◊ö'],
    'balcony': ['balcony', 'terrace', '◊û◊®◊§◊°◊™'],
    'rooftop': ['rooftop', 'roof', '◊í◊í', '◊í◊í ◊¢◊ô◊®◊ï◊†◊ô']
}

# ---------------------------
# App & Globals
# ---------------------------
app = FastAPI(title="Google Drive AI Search v3 (with YOLOv8)")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:4000", "http://127.0.0.1:4000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global exception handler to prevent crashes
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    print(f"‚ùå Global exception caught: {exc}")
    import traceback
    print(f"üìã Full traceback: {traceback.format_exc()}")
    return JSONResponse(
        status_code=500,
        content={"error": "Internal server error", "detail": str(exc)}
    )

# Add middleware to handle CORS and other issues
@app.middleware("http")
async def add_cors_and_error_handling(request: Request, call_next):
    """Add CORS headers and handle errors gracefully"""
    try:
        response = await call_next(request)
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "*"
        return response
    except Exception as e:
        print(f"‚ùå Middleware error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Request processing error"},
            headers={"Access-Control-Allow-Origin": "*"}
        )

# Session storage for authentication
auth_sessions = {}

# Connection cache to avoid repeated authentication
_connection_cache = {
    "last_auth_time": None,
    "auth_duration": None,
    "cached_session": None
}

def refresh_credentials_if_needed(creds):
    """Refresh credentials if they are expired or about to expire"""
    if not creds or not creds.expired:
        return creds
    
    try:
        print("üîÑ Refreshing expired credentials...")
        from google.auth.transport.requests import Request
        creds.refresh(Request())
        print("‚úÖ Credentials refreshed successfully")
        return creds
    except Exception as e:
        print(f"‚ùå Failed to refresh credentials: {e}")
        return None

SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

# OpenAI API Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY
else:
    print("‚ö†Ô∏è Warning: OPENAI_API_KEY environment variable not set. AI features will be disabled.")

def save_credentials_to_session(session_id: str, credentials: Credentials):
    """Save credentials to session storage"""
    auth_sessions[session_id] = {
        'credentials': credentials,
        'timestamp': time.time(),
        'expires_at': time.time() + 3600  # 1 hour
    }

def load_credentials_from_session(session_id: str) -> Credentials:
    """Load credentials from session storage and refresh if needed"""
    if session_id not in auth_sessions:
        return None
    
    session = auth_sessions[session_id]
    creds = session['credentials']
    
    # Try to refresh credentials if they're expired
    refreshed_creds = refresh_credentials_if_needed(creds)
    if refreshed_creds:
        # Update the session with refreshed credentials
        auth_sessions[session_id]['credentials'] = refreshed_creds
        auth_sessions[session_id]['timestamp'] = time.time()
        auth_sessions[session_id]['expires_at'] = time.time() + 3600  # 1 hour
        return refreshed_creds
    else:
        # If refresh failed, clear the session
        del auth_sessions[session_id]
        return None

def clear_session(session_id: str):
    """Clear session data"""
    if session_id in auth_sessions:
        del auth_sessions[session_id]

drive_service = None
image_index = {}  # {file_id: {'name': str, 'embedding': tensor, 'objects': [], 'colors': []}}

def create_company_logo():
    """Create the Idan Locations company logo as an image"""
    try:
        # Create logo image with company branding
        img = Image.new('RGB', (400, 120), color='black')
        draw = ImageDraw.Draw(img)
        
        # Try to use a default font, fallback to basic if not available
        try:
            title_font = ImageFont.truetype("arial.ttf", 32)
            subtitle_font = ImageFont.truetype("arial.ttf", 24)
        except:
            title_font = ImageFont.load_default()
            subtitle_font = ImageFont.load_default()
        
        # Company name colors (teal with orange outline)
        teal_color = (0, 128, 128)  # Dark teal
        orange_color = (255, 165, 0)  # Orange
        
        # Draw "Idan" with outline effect
        idan_text = "Idan"
        idan_bbox = draw.textbbox((0, 0), idan_text, font=title_font)
        idan_width = idan_bbox[2] - idan_bbox[0]
        idan_height = idan_bbox[3] - idan_bbox[1]
        
        # Draw outline (orange)
        for dx in [-2, -1, 0, 1, 2]:
            for dy in [-2, -1, 0, 1, 2]:
                if dx != 0 or dy != 0:
                    draw.text((20 + dx, 20 + dy), idan_text, fill=orange_color, font=title_font)
        
        # Draw main text (teal)
        draw.text((20, 20), idan_text, fill=teal_color, font=title_font)
        
        # Draw "Locations" with outline effect
        locations_text = "Locations"
        locations_bbox = draw.textbbox((0, 0), locations_text, font=subtitle_font)
        locations_width = locations_bbox[2] - locations_bbox[0]
        
        # Draw outline (orange)
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx != 0 or dy != 0:
                    draw.text((20 + dx, 60 + dy), locations_text, fill=orange_color, font=subtitle_font)
        
        # Draw main text (teal)
        draw.text((20, 60), locations_text, fill=teal_color, font=subtitle_font)
        
        # Draw a simple location pin icon (orange carrot-like shape)
        pin_x = 300
        pin_y = 40
        
        # Draw pin body (carrot shape)
        pin_points = [
            (pin_x, pin_y + 40),  # Bottom point
            (pin_x - 15, pin_y + 20),  # Left side
            (pin_x - 10, pin_y),  # Top left
            (pin_x + 10, pin_y),  # Top right
            (pin_x + 15, pin_y + 20)  # Right side
        ]
        draw.polygon(pin_points, fill=orange_color)
        
        # Draw leaves on top (green)
        leaf_color = (0, 150, 0)
        draw.ellipse([pin_x - 8, pin_y - 5, pin_x - 2, pin_y + 5], fill=leaf_color)
        draw.ellipse([pin_x + 2, pin_y - 5, pin_x + 8, pin_y + 5], fill=leaf_color)
        
        # Draw camera aperture in center of pin
        aperture_center = (pin_x, pin_y + 15)
        aperture_radius = 8
        draw.ellipse([
            aperture_center[0] - aperture_radius, 
            aperture_center[1] - aperture_radius,
            aperture_center[0] + aperture_radius, 
            aperture_center[1] + aperture_radius
        ], fill='black', outline=orange_color, width=2)
        
        # Save to bytes
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='PNG')
        img_bytes.seek(0)
        return img_bytes.getvalue()
        
    except Exception as e:
        print(f"Error creating company logo: {e}")
        # Return a simple text-based logo as fallback
        img = Image.new('RGB', (300, 80), color='black')
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.truetype("arial.ttf", 24)
        except:
            font = ImageFont.load_default()
        draw.text((50, 30), "Idan Locations", fill='white', font=font)
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='PNG')
        img_bytes.seek(0)
        return img_bytes.getvalue()

def create_placeholder_image():
    """Create a placeholder image when the real image fails to load"""
    try:
        # Create a simple placeholder image
        img = Image.new('RGB', (300, 200), color='lightgray')
        draw = ImageDraw.Draw(img)
        
        # Try to use a default font, fallback to basic if not available
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()
        
        # Draw placeholder text
        text = "Image\nNot Available"
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        x = (300 - text_width) // 2
        y = (200 - text_height) // 2
        
        draw.text((x, y), text, fill='darkgray', font=font)
        
        # Convert to bytes
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='PNG')
        img_bytes.seek(0)
        return img_bytes.getvalue()
    except Exception as e:
        print(f"‚ùå Failed to create placeholder image: {e}")
        # Return a minimal 1x1 pixel image
        return b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\tpHYs\x00\x00\x0b\x13\x00\x00\x0b\x13\x01\x00\x9a\x9c\x18\x00\x00\x00\nIDATx\x9cc```\x00\x00\x00\x04\x00\x01\xdd\x8d\xb4\x1c\x00\x00\x00\x00IEND\xaeB`\x82'

device = "cuda" if torch.cuda.is_available() else "cpu"

# Hebrew-English mapping for enhanced search
HEBREW_ENGLISH_MAPPING = {
    # 1. ◊°◊ï◊í◊ô ◊ó◊ì◊®◊ô◊ù (Room Types)
    '◊°◊ú◊ï◊ü': 'living room',
    '◊û◊ò◊ë◊ó': 'kitchen', 
    '◊§◊ô◊†◊™ ◊ê◊ï◊õ◊ú': 'dining area',
    '◊ó◊ì◊® ◊©◊ô◊†◊î ◊®◊ê◊©◊ô': 'master bedroom',
    '◊ó◊ì◊® ◊©◊ô◊†◊î ◊ô◊ú◊ì◊ô◊ù': 'children bedroom',
    '◊ó◊ì◊® ◊¢◊ë◊ï◊ì◊î': 'office',
    '◊ó◊ì◊® ◊®◊ó◊¶◊î ◊®◊ê◊©◊ô': 'master bathroom',
    '◊ó◊ì◊® ◊®◊ó◊¶◊î ◊ê◊ï◊®◊ó◊ô◊ù': 'guest bathroom',
    '◊ó◊ì◊® ◊û◊©◊ó◊ß◊ô◊ù': 'playroom',
    '◊û◊®◊§◊°◊™ ◊°◊í◊ï◊®◊î': 'covered balcony',
    '◊ó◊¶◊®': 'yard',
    '◊ë◊®◊ô◊õ◊î': 'pool',
    
    # 2. ◊û◊ë◊†◊î ◊ï◊™◊õ◊†◊ï◊ü ◊ó◊ú◊ú (Structure and Space Planning)
    '◊°◊ú◊ï◊ü ◊§◊™◊ï◊ó ◊ú◊û◊ò◊ë◊ó': 'open living kitchen',
    '◊û◊ò◊ë◊ó ◊¢◊ù ◊ê◊ô': 'kitchen with island',
    '◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î': 'high ceiling',
    '◊™◊ß◊®◊™ ◊¢◊•': 'wooden ceiling',
    '◊ó◊ú◊ï◊†◊ï◊™ ◊§◊†◊ï◊®◊û◊ô◊ô◊ù': 'panoramic windows',
    '◊ó◊ì◊® ◊¢◊ù ◊í◊ú◊®◊ô◊î': 'room with gallery',
    '◊ì◊ú◊™◊ï◊™ ◊î◊ñ◊ñ◊î ◊û◊ñ◊õ◊ï◊õ◊ô◊™': 'sliding glass doors',
    '◊û◊°◊ì◊®◊ï◊ü ◊ê◊®◊ï◊ö': 'long corridor',
    '◊ó◊ì◊® ◊¢◊ù ◊ß◊ô◊®◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™': 'room with glass walls',
    '◊ß◊ô◊® ◊û◊ó◊ô◊¶◊î ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô': 'decorative partition wall',
    
    # 3. ◊°◊ï◊í◊ô ◊®◊ô◊¶◊ï◊£ (Flooring Types)
    '◊§◊®◊ß◊ò ◊¢◊• ◊ò◊ë◊¢◊ô': 'natural wood parquet',
    '◊ë◊ò◊ï◊ü ◊û◊ï◊ó◊ú◊ß': 'polished concrete',
    '◊ê◊®◊ô◊ó◊ô ◊ß◊®◊û◊ô◊ß◊î': 'ceramic tiles',
    '◊®◊¶◊§◊™ ◊©◊ô◊©': 'marble floor',
    '◊©◊ò◊ô◊ó◊ô◊ù ◊û◊ß◊ô◊® ◊ú◊ß◊ô◊®': 'wall to wall carpet',
    '◊®◊¶◊§◊™ ◊ò◊®◊¶◊ï': 'terrazzo floor',
    '◊®◊¶◊§◊™ ◊ú◊ô◊†◊ï◊ú◊ô◊ê◊ï◊ù': 'linoleum floor',
    '◊®◊¶◊§◊™ ◊¢◊• ◊ú◊û◊ô◊†◊¶◊ô◊î': 'laminate wood floor',
    '◊®◊¶◊§◊™ ◊ê◊§◊ï◊ß◊°◊ô': 'epoxy floor',
    '◊û◊®◊¶◊§◊ï◊™ ◊û◊¶◊ï◊ô◊®◊ï◊™': 'painted tiles',
    
    # 4. ◊°◊í◊†◊ï◊ü ◊¢◊ô◊¶◊ï◊ë◊ô (Design Style)
    '◊û◊ï◊ì◊®◊†◊ô': 'modern',
    '◊õ◊§◊®◊ô': 'rustic',
    '◊™◊¢◊©◊ô◊ô◊™◊ô': 'industrial',
    '◊°◊ß◊†◊ì◊ô◊†◊ë◊ô': 'scandinavian',
    '◊ê◊ß◊ú◊ß◊ò◊ô': 'eclectic',
    '◊û◊ô◊†◊ô◊û◊ú◊ô◊°◊ò◊ô': 'minimalist',
    '◊®◊ò◊®◊ï': 'retro',
    '◊ï◊ô◊†◊ò◊í': 'vintage',
    '◊ë◊ï◊î◊ï ◊©◊ô◊ß': 'boho chic',
    '◊¢◊ô◊¶◊ï◊ë ◊ê◊ï◊®◊ë◊†◊ô': 'urban design',
    
    # 5. ◊ó◊ï◊û◊®◊ô ◊í◊û◊® (Finishing Materials)
    '◊ß◊ô◊®◊ï◊™ ◊ë◊ò◊ï◊ü ◊ó◊©◊ï◊£': 'exposed concrete walls',
    '◊¢◊• ◊û◊ú◊ê': 'solid wood',
    '◊ñ◊õ◊ï◊õ◊ô◊™ ◊û◊ó◊ï◊°◊û◊™': 'tempered glass',
    '◊§◊ú◊ô◊ñ ◊û◊ë◊®◊ô◊ß': 'polished brass',
    '◊ë◊®◊ñ◊ú ◊©◊ó◊ï◊®': 'black iron',
    '◊¢◊ï◊® ◊ê◊ô◊õ◊ï◊™◊ô': 'quality leather',
    '◊ê◊®◊ô◊ó◊ô◊ù ◊û◊ê◊ë◊ü ◊ò◊ë◊¢◊ô◊™': 'natural stone tiles',
    '◊ò◊ô◊ó ◊û◊ô◊†◊®◊ú◊ô': 'mineral plaster',
    '◊ò◊§◊ò◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù': 'decorative wallpaper',
    '◊û◊™◊õ◊™ ◊ê◊ú◊ï◊û◊ô◊†◊ô◊ï◊ù': 'aluminum metal',
    
    # 6. ◊™◊ß◊®◊ï◊™ (Ceilings)
    '◊™◊ß◊®◊î ◊¢◊ù ◊ß◊ï◊®◊ï◊™ ◊¢◊•': 'ceiling with wooden beams',
    '◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î': 'high ceiling',
    '◊™◊ß◊®◊î ◊†◊û◊ï◊õ◊î': 'low ceiling',
    '◊™◊ß◊®◊î ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊†◊°◊™◊®◊™': 'ceiling with hidden lighting',
    '◊™◊ß◊®◊™ ◊í◊ë◊° ◊û◊¢◊ï◊¶◊ë◊™': 'designed plaster ceiling',
    '◊™◊ß◊®◊î ◊û◊©◊ï◊§◊¢◊™': 'sloped ceiling',
    '◊™◊ß◊®◊î ◊û◊ß◊ï◊û◊®◊™': 'arched ceiling',
    '◊™◊ß◊®◊™ ◊ñ◊õ◊ï◊õ◊ô◊™': 'glass ceiling',
    '◊™◊ß◊®◊î ◊¢◊ù ◊ó◊ú◊ï◊ü ◊í◊í': 'ceiling with skylight',
    '◊™◊ß◊®◊î ◊ê◊ß◊ï◊°◊ò◊ô◊™': 'acoustic ceiling',
    
    # 7. ◊§◊™◊ó◊ô◊ù ◊ï◊û◊¢◊ë◊®◊ô◊ù (Openings and Transitions)
    '◊ó◊ú◊ï◊†◊ï◊™ ◊ß◊ô◊®-◊ú◊ß◊ô◊®': 'wall to wall windows',
    '◊ì◊ú◊™◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™': 'glass doors',
    '◊ó◊ú◊ï◊†◊ï◊™ ◊ë◊ú◊í◊ô◊ô◊ù': 'Belgian windows',
    '◊§◊™◊ó◊ô◊ù ◊¢◊í◊ï◊ú◊ô◊ù': 'round openings',
    '◊ì◊ú◊™◊ï◊™ ◊¢◊• ◊û◊ú◊ê': 'solid wood doors',
    '◊™◊®◊ô◊°◊ô◊ù ◊û◊¢◊•': 'wooden shutters',
    '◊ó◊ú◊ï◊†◊ï◊™ ◊¢◊ù ◊û◊°◊í◊®◊™ ◊û◊™◊õ◊™': 'windows with metal frame',
    '◊ó◊ú◊ï◊†◊ï◊™ ◊í◊í': 'skylights',
    '◊ì◊ú◊™◊ï◊™ ◊§◊ú◊ì◊î': 'steel doors',
    '◊§◊™◊ó◊ô ◊™◊ê◊ï◊®◊î ◊ë◊™◊ß◊®◊î': 'ceiling light openings',
    
    # 8. ◊ß◊ï◊û◊ï◊™ ◊ï◊û◊ë◊†◊î (Floors and Structure)
    '◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊™ ◊ß◊®◊ß◊¢': 'ground floor apartment',
    '◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊î ◊¢◊ú◊ô◊ï◊†◊î': 'top floor apartment',
    '◊ì◊ï◊§◊ú◊ß◊°': 'duplex',
    '◊†◊ò◊î◊ê◊ï◊ñ': 'penthouse',
    '◊ú◊ï◊§◊ò': 'loft',
    '◊ï◊ô◊ú◊î ◊¢◊ô◊®◊ï◊†◊ô◊™': 'urban villa',
    '◊ß◊ï◊ò◊í ◊§◊®◊ë◊®◊ô': 'suburban cottage',
    '◊ë◊ô◊™ ◊ú◊©◊ô◊û◊ï◊®': 'heritage house',
    '◊û◊ë◊†◊î ◊™◊¢◊©◊ô◊ô◊™◊ô': 'industrial building',
    '◊û◊ë◊†◊î ◊û◊ï◊ì◊®◊†◊ô': 'modern building',
    
    # 9. ◊™◊ê◊ï◊®◊î (Lighting)
    '◊™◊ê◊ï◊®◊î ◊ò◊ë◊¢◊ô◊™': 'natural lighting',
    '◊™◊ê◊ï◊®◊™ ◊ú◊ì ◊†◊°◊™◊®◊™': 'hidden LED lighting',
    '◊û◊†◊ï◊®◊ï◊™ ◊™◊ß◊®◊î ◊û◊¢◊ï◊¶◊ë◊ï◊™': 'designed ceiling lights',
    '◊û◊†◊ï◊®◊ï◊™ ◊ß◊ô◊®': 'wall lights',
    '◊™◊ê◊ï◊®◊™ ◊ê◊ï◊ï◊ô◊®◊î': 'ambient lighting',
    '◊™◊ê◊ï◊®◊î ◊û◊™◊õ◊ï◊ï◊†◊†◊™': 'adjustable lighting',
    '◊™◊ê◊ï◊®◊™ ◊§◊ú◊ï◊®◊°◊†◊ò': 'fluorescent lighting',
    '◊†◊ë◊®◊©◊ï◊™ ◊ß◊®◊ô◊°◊ò◊ú': 'crystal chandeliers',
    '◊™◊ê◊ï◊®◊™ ◊©◊ï◊ú◊ó◊ü': 'table lighting',
    '◊™◊ê◊ï◊®◊™ ◊ó◊ï◊•': 'outdoor lighting',
    
    # 10. ◊®◊ô◊î◊ï◊ò (Furniture)
    '◊°◊§◊ï◊™ ◊¢◊ï◊®': 'leather sofas',
    '◊©◊ï◊ú◊ó◊ü ◊ê◊ï◊õ◊ú ◊û◊¢◊• ◊û◊ú◊ê': 'solid wood dining table',
    '◊©◊ï◊ú◊ó◊ü ◊ß◊§◊î': 'coffee table',
    '◊õ◊ï◊®◊°◊ê◊ï◊™ ◊ë◊ì': 'fabric armchairs',
    '◊õ◊°◊ê◊ï◊™ ◊ë◊®': 'bar stools',
    '◊û◊ô◊ò◊î ◊ñ◊ï◊í◊ô◊™': 'double bed',
    '◊ê◊®◊ï◊ü ◊ß◊ô◊®': 'wall wardrobe',
    '◊û◊ì◊§◊ô◊ù ◊§◊™◊ï◊ó◊ô◊ù': 'open shelves',
    '◊§◊ô◊†◊™ ◊ô◊©◊ô◊ë◊î': 'seating area',
    '◊©◊ï◊ú◊ó◊ü ◊¢◊ë◊ï◊ì◊î': 'work desk',
    
    # 11. ◊ß◊ô◊®◊ï◊™ (Walls)
    '◊ß◊ô◊® ◊ú◊ë◊†◊ô◊ù ◊ó◊©◊ï◊£': 'exposed brick wall',
    '◊ß◊ô◊® ◊¢◊ù ◊ò◊§◊ò◊ô◊ù': 'wall with wallpaper',
    '◊ß◊ô◊® ◊¶◊ë◊¢◊ï◊†◊ô': 'colored wall',
    '◊ß◊ô◊® ◊¢◊ù ◊ê◊®◊ô◊ó◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù': 'wall with decorative tiles',
    '◊ß◊ô◊® ◊¢◊ù ◊™◊û◊ï◊†◊ï◊™ ◊ê◊û◊†◊ï◊™': 'wall with art pictures',
    '◊ß◊ô◊® ◊¢◊ù ◊û◊®◊ê◊î ◊í◊ì◊ï◊ú◊î': 'wall with large mirror',
    '◊ß◊ô◊® ◊û◊¢◊• ◊ò◊ë◊¢◊ô': 'natural wood wall',
    '◊ß◊ô◊® ◊¢◊ù ◊ì◊ú◊™◊ï◊™ ◊†◊°◊™◊®◊ï◊™': 'wall with hidden doors',
    '◊ß◊ô◊® ◊í◊ë◊° ◊ê◊ß◊ï◊°◊ò◊ô': 'acoustic plaster wall',
    '◊ß◊ô◊® ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊§◊†◊ô◊û◊ô◊™': 'wall with internal lighting',
    
    # 12. ◊ó◊¶◊® ◊ï◊í◊ô◊†◊î (Yard and Garden)
    '◊í◊ô◊†◊î ◊§◊®◊ò◊ô◊™': 'private garden',
    '◊í◊ô◊†◊î ◊ê◊ï◊®◊ë◊†◊ô◊™': 'urban garden',
    '◊û◊®◊§◊°◊™ ◊™◊ú◊ï◊ô◊î': 'hanging balcony',
    '◊ó◊¶◊® ◊§◊†◊ô◊û◊ô◊™': 'inner courtyard',
    '◊í◊í ◊ô◊®◊ï◊ß': 'green roof',
    '◊ì◊ß ◊¢◊•': 'wooden deck',
    '◊ê◊ñ◊ï◊® ◊ô◊©◊ô◊ë◊î ◊ó◊ô◊¶◊ï◊†◊ô': 'outdoor seating area',
    '◊ë◊®◊ô◊õ◊™ ◊©◊ó◊ô◊ô◊î ◊§◊®◊ò◊ô◊™': 'private swimming pool',
    '◊í◊ô◊†◊î ◊ô◊ù-◊™◊ô◊õ◊ï◊†◊ô◊™': 'Mediterranean garden',
    '◊©◊ë◊ô◊ú◊ô ◊í◊ô◊†◊î ◊û◊®◊ï◊¶◊§◊ô◊ù': 'paved garden paths',
    
    # 13. ◊ê◊ß◊°◊°◊ï◊®◊ô◊ñ ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù (Decorative Accessories)
    '◊õ◊®◊ô◊ï◊™ ◊†◊ï◊ô': 'decorative cushions',
    '◊©◊ò◊ô◊ó◊ô◊ù ◊û◊¢◊ï◊¶◊ë◊ô◊ù': 'designed rugs',
    '◊™◊û◊ï◊†◊ï◊™ ◊ß◊ô◊®': 'wall pictures',
    '◊ï◊ô◊ú◊ï◊†◊ï◊™ ◊ë◊ì': 'fabric curtains',
    '◊§◊°◊ú◊ô◊ù ◊û◊ï◊ì◊®◊†◊ô◊ô◊ù': 'modern sculptures',
    '◊†◊®◊ï◊™ ◊®◊ô◊ó◊†◊ô◊ô◊ù': 'scented candles',
    '◊ê◊í◊®◊ò◊ú◊ô◊ù ◊ñ◊õ◊ï◊õ◊ô◊™': 'glass vases',
    '◊û◊®◊ê◊ï◊™ ◊û◊¢◊ï◊¶◊ë◊ï◊™': 'designed mirrors',
    '◊õ◊ú◊ô ◊ó◊®◊°': 'ceramic vessels',
    '◊¢◊¶◊ô◊¶◊ô◊ù ◊ï◊¶◊û◊ó◊ô◊ù ◊ô◊®◊ï◊ß◊ô◊ù': 'pots and green plants',
    
    # 14. ◊¶◊ë◊¢◊ï◊†◊ô◊ï◊™ (Color Palette)
    '◊û◊ï◊†◊ï◊õ◊®◊ï◊û◊ò◊ô': 'monochromatic',
    '◊í◊ï◊ï◊†◊ô ◊§◊°◊ò◊ú': 'pastel tones',
    '◊¶◊ë◊¢◊ô◊ù ◊†◊ô◊ò◊®◊ú◊ô◊ô◊ù': 'neutral colors',
    '◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ó◊û◊î': 'warm color palette',
    '◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ß◊®◊î': 'cool color palette',
    '◊í◊ï◊ï◊†◊ô◊ù ◊õ◊î◊ô◊ù ◊ï◊¢◊©◊ô◊®◊ô◊ù': 'dark and rich tones',
    '◊ß◊ô◊®◊ï◊™ ◊¶◊ë◊¢◊ï◊†◊ô◊ô◊ù': 'colored walls',
    '◊†◊ô◊í◊ï◊ì◊ô ◊©◊ó◊ï◊® ◊ï◊ú◊ë◊ü': 'black and white contrasts',
    '◊¶◊ë◊¢◊ô ◊ê◊ì◊û◊î': 'earth colors',
    '◊í◊ï◊ï◊†◊ô◊ù ◊ë◊î◊ô◊®◊ô◊ù ◊ï◊û◊ê◊ï◊ï◊®◊®◊ô◊ù': 'bright and airy tones',
    
    # 15. ◊ê◊ï◊§◊ô ◊î◊ó◊ú◊ú (Space Character)
    '◊ó◊ú◊ú ◊§◊™◊ï◊ó': 'open space',
    '◊ó◊ú◊ú ◊®◊ë-◊™◊õ◊ú◊ô◊™◊ô': 'multi-purpose space',
    '◊ó◊ú◊ú ◊ê◊ô◊†◊ò◊ô◊û◊ô': 'intimate space',
    '◊ó◊ú◊ú ◊¢◊ù ◊ñ◊®◊ô◊û◊î ◊ò◊ë◊¢◊ô◊™': 'space with natural flow',
    '◊ó◊ú◊ú ◊®◊©◊û◊ô': 'formal space',
    '◊ó◊ú◊ú ◊û◊ó◊ï◊ú◊ß ◊ë◊ê◊ú◊í◊†◊ò◊ô◊ï◊™': 'elegantly divided space',
    '◊ó◊ú◊ú ◊¢◊ù ◊†◊ï◊£ ◊§◊™◊ï◊ó': 'space with open view',
    '◊ó◊ú◊ú ◊û◊®◊ï◊ï◊ó': 'spacious area',
    '◊ó◊ú◊ú ◊ß◊ï◊û◊§◊ß◊ò◊ô': 'compact space',
    '◊ó◊ú◊ú ◊û◊ï◊ê◊® ◊î◊ô◊ò◊ë': 'well-lit space',
    
}

# CLIP model via transformers
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
clip_model.to(device)

# YOLOv8 model
yolo_model = YOLO("yolov8n.pt")  # small model, replace with custom if needed

# ---------------------------
# Utilities
# ---------------------------
def extract_dominant_colors(image, num_colors=3):
    """Extract dominant colors from image using KMeans clustering"""
    img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    img = cv2.resize(img, (100, 100))  # resize for speed
    img = img.reshape((-1, 3)).astype(np.float32)
    
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
    _, labels, centers = cv2.kmeans(img, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
    colors = [tuple(map(int, center)) for center in centers]
    return colors

def detect_objects_yolo(image):
    """Detect objects in image using YOLOv8"""
    results = yolo_model.predict(np.array(image))
    objs = []
    for r in results:
        for box in r.boxes:
            cls = int(box.cls)
            name = yolo_model.names[cls]
            objs.append(name.lower())
    return objs

def color_match_score(dominant_colors, target_colors_rgb):
    """Compute color match score between dominant colors and target colors"""
    if not target_colors_rgb or not dominant_colors:
        return 1.0
    
    score = 0
    for target in target_colors_rgb:
        # Calculate distance to closest dominant color
        distances = [float(np.linalg.norm(np.array(c) - np.array(target))) for c in dominant_colors]
        min_distance = min(distances) if distances else 1.0
        
        # Normalize distance (max possible distance in RGB space is sqrt(3*255^2))
        max_distance = np.sqrt(3 * 255**2)
        normalized_distance = min_distance / max_distance
        
        # Convert to similarity score (closer = higher score)
        similarity = max(0, 1 - normalized_distance)
        score += similarity
    
    return score / len(target_colors_rgb)

def detect_room_types(objects):
    """Enhanced room type detection based on detected objects"""
    detected_rooms = []
    object_lower = [obj.lower() for obj in objects]
    object_text = ' '.join(object_lower)
    
    # Enhanced room detection with weighted scoring
    room_scores = {}
    
    # Kitchen indicators (high weight for distinctive items)
    kitchen_score = 0
    kitchen_keywords = ['sink', 'refrigerator', 'oven', 'microwave', 'toaster', 'knife', 'bowl', 'cup', 'bottle', 'wine glass', 'dining table', 'stove', 'dishwasher']
    for keyword in kitchen_keywords:
        if keyword in object_text:
            weight = 3 if keyword in ['sink', 'refrigerator', 'oven', 'stove'] else 1
            kitchen_score += weight
    if kitchen_score > 0:
        room_scores['kitchen'] = kitchen_score
    
    # Bedroom indicators
    bedroom_score = 0
    bedroom_keywords = ['bed', 'pillow', 'lamp', 'clock', 'dresser', 'wardrobe']
    for keyword in bedroom_keywords:
        if keyword in object_text:
            weight = 5 if keyword == 'bed' else 1
            bedroom_score += weight
    if bedroom_score > 0:
        room_scores['bedroom'] = bedroom_score
    
    # Bathroom indicators
    bathroom_score = 0
    bathroom_keywords = ['toilet', 'sink', 'towel', 'soap', 'toothbrush', 'bathtub', 'shower']
    for keyword in bathroom_keywords:
        if keyword in object_text:
            weight = 5 if keyword == 'toilet' else 2 if keyword == 'sink' else 1
            bathroom_score += weight
    if bathroom_score > 0:
        room_scores['bathroom'] = bathroom_score
    
    # Living room indicators
    living_score = 0
    living_keywords = ['couch', 'tv', 'remote', 'coffee table', 'book', 'vase', 'sofa', 'armchair']
    for keyword in living_keywords:
        if keyword in object_text:
            weight = 3 if keyword in ['couch', 'tv', 'sofa'] else 1
            living_score += weight
    if living_score > 0:
        room_scores['living room'] = living_score
    
    # Dining room indicators
    dining_score = 0
    dining_keywords = ['dining table', 'chair', 'wine glass', 'bottle', 'plate', 'fork', 'spoon']
    for keyword in dining_keywords:
        if keyword in object_text:
            weight = 3 if keyword == 'dining table' else 1
            dining_score += weight
    if dining_score > 0:
        room_scores['dining room'] = dining_score
    
    # Office indicators
    office_score = 0
    office_keywords = ['laptop', 'keyboard', 'mouse', 'monitor', 'book', 'chair', 'desk', 'computer']
    for keyword in office_keywords:
        if keyword in object_text:
            weight = 3 if keyword in ['laptop', 'computer', 'desk'] else 1
            office_score += weight
    if office_score > 0:
        room_scores['office'] = office_score
    
    # Return rooms sorted by score (highest first)
    if room_scores:
        sorted_rooms = sorted(room_scores.items(), key=lambda x: x[1], reverse=True)
        detected_rooms = [room for room, score in sorted_rooms if score > 0]
    
    return detected_rooms

def analyze_storyboard_image(img):
    """Analyze a storyboard image and extract features"""
    # CLIP embedding
    inputs = clip_processor(images=img, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        image_features = clip_model.get_image_features(**inputs)
        embedding = image_features / image_features.norm(dim=-1, keepdim=True)
    
    # Extract dominant colors
    colors = extract_dominant_colors(img)
    
    # YOLO object detection
    objects = detect_objects_yolo(img)
    
    # Detect room types
    suggested_rooms = detect_room_types(objects)
    
    return {
        'embedding': embedding.cpu(),
        'objects': objects,
        'colors': colors,
        'suggested_rooms': suggested_rooms
    }

def translate_hebrew_query(query):
    """Translate Hebrew terms to English for better CLIP understanding"""
    translated_query = query
    
    # Check for Hebrew terms and translate them
    for hebrew_term, english_term in HEBREW_ENGLISH_MAPPING.items():
        if hebrew_term in query:
            translated_query = translated_query.replace(hebrew_term, english_term)
    
    return translated_query

def calculate_combined_score(semantic_score, object_score, color_score, weights=None):
    """Calculate combined score with configurable weights"""
    if weights is None:
        weights = {"semantic": 0.6, "object": 0.2, "color": 0.2}
    
    # Ensure scores are in valid range [0, 1]
    semantic_score = max(0, min(1, semantic_score))
    object_score = max(0, min(1, object_score))
    color_score = max(0, min(1, color_score))
    
    combined = (
        semantic_score * weights["semantic"] +
        object_score * weights["object"] +
        color_score * weights["color"]
    )
    
    return combined

# ---------------------------
# 1Ô∏è‚É£ Authenticate with Google Drive
# ---------------------------
@app.get("/auth")
def auth_drive():
    """Authenticate with Google Drive using Service Account or OAuth2"""
    global drive_service

    # Check if we already have a working connection
    last_auth_time = _connection_cache.get("last_auth_time")
    if drive_service and last_auth_time:
        import time
        time_since_auth = time.time() - last_auth_time
        if time_since_auth < 300:  # 5 minutes cache
            print("üöÄ Using cached Google Drive connection")
            return {
                "status": "authenticated",
                "message": "Using cached Google Drive connection",
                "session_id": _connection_cache.get("cached_session"),
                "method": "cached",
                "cached_duration": int(time_since_auth)
            }

    try:
        # Try service account first (more reliable for server applications)
        service_account_file = "secret-spark-432817-r3-e78bdaac1d51.json"
        if os.path.exists(service_account_file):
            print("üîê Using service account authentication...")
            from google.oauth2 import service_account
            creds = service_account.Credentials.from_service_account_file(
                service_account_file,
                scopes=['https://www.googleapis.com/auth/drive.readonly']
            )
            drive_service = build('drive', 'v3', credentials=creds)

            # Test the connection with timeout
            try:
                print("üîó Testing Google Drive connection...")
                import concurrent.futures
                
                # Quick connection test with timeout
                def test_connection():
                    try:
                        if drive_service:
                            return drive_service.files().list(pageSize=1).execute()
                        return None
                    except Exception as e:
                        print(f"‚ùå Connection test failed: {e}")
                        return None
                
                # Use thread pool with timeout for connection test
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(test_connection)
                    try:
                        results = future.result(timeout=10)  # 10 second timeout
                        if results is None:
                            raise Exception("Connection test returned None")
                    except concurrent.futures.TimeoutError:
                        print("‚è∞ Connection test timed out, but service account should still work")
                        results = {"files": []}  # Assume connection works
                
                print("‚úÖ Google Drive connection successful")
                session_id = str(uuid.uuid4())
                save_credentials_to_session(session_id, creds)
                
                # Cache the connection
                import time
                _connection_cache["last_auth_time"] = time.time()
                _connection_cache["cached_session"] = session_id

                return {
                    "status": "authenticated",
                    "message": "Successfully connected to Google Drive via Service Account",
                    "session_id": session_id,
                    "method": "service_account"
                }
            except HttpError as e:
                return {"error": f"Service Account connection failed: {str(e)}"}

                # Try OAuth with NEW client secret first
                new_client_secret_file = "client_secret_132538948811-qim43q7uu42eh2vskk1f4g2n3koa8ong.apps.googleusercontent.com.json"
                if os.path.exists(new_client_secret_file):
                    print("üîê Using NEW OAuth client secret...")
                    try:
                        print(f"üìÅ Loading OAuth file: {new_client_secret_file}")
                        flow = InstalledAppFlow.from_client_secrets_file(
                            new_client_secret_file,
                            scopes=['https://www.googleapis.com/auth/drive.readonly']
                        )
                        # Enable offline access for refresh tokens
                        flow.redirect_uri = 'http://localhost:8080/callback'
                        print("‚úÖ OAuth flow created successfully")
                        
                        print("üåê Starting OAuth server on port 0...")
                        creds = flow.run_local_server(port=0)
                        print("‚úÖ OAuth authentication completed")
                        
                        print("üîß Building Drive service...")
                        drive_service = build('drive', 'v3', credentials=creds)
                        print("‚úÖ Drive service built")
                        
                        # Test the connection
                        print("üß™ Testing Drive API connection...")
                        results = drive_service.files().list(pageSize=1).execute()
                        print(f"‚úÖ Drive API test successful - found {len(results.get('files', []))} files")
                        
                        session_id = str(uuid.uuid4())
                        save_credentials_to_session(session_id, creds)
                        print(f"üíæ Session saved: {session_id}")

                        return {
                            "status": "authenticated",
                            "message": "Successfully connected to Google Drive via NEW OAuth",
                            "session_id": session_id,
                            "method": "oauth_new",
                            "debug": {
                                "oauth_file": new_client_secret_file,
                                "files_found": len(results.get('files', [])),
                                "session_id": session_id
                            }
                        }
                    except Exception as e:
                        print(f"‚ùå NEW OAuth error: {str(e)}")
                        import traceback
                        print(f"üìã Full traceback: {traceback.format_exc()}")
                        return {
                            "error": f"NEW OAuth authentication failed: {str(e)}",
                            "debug": {
                                "oauth_file": new_client_secret_file,
                                "error_type": type(e).__name__,
                                "traceback": traceback.format_exc()
                            }
                        }

        # Fallback to old client secret
        old_client_secret_file = "client_secret_1012576941399-515ln173s773sbrrpn3gtmek0d5vc0u5.apps.googleusercontent.com.json"
        if os.path.exists(old_client_secret_file):
            print("üîê Old client secret found, but OAuth requires browser interaction.")
            return {
                "error": "OAuth authentication requires browser interaction. Please use the service account or run this in an interactive environment."
            }

        # Fallback to standard credentials.json
        oauth_file = "credentials.json"
        if os.path.exists(oauth_file):
            print("üîê Using OAuth with credentials.json...")
            return {
                "error": "OAuth requires browser interaction. Please use the service account or run this in an interactive environment."
            }

    except FileNotFoundError:
        return {"error": "No valid credentials found. Please ensure one of: credentials.json, service account JSON, or client secret JSON is present"}
    except Exception as e:
        return {"error": f"Authentication failed: {str(e)}"}

@app.get("/auth/status")
def check_auth_status(session_id: str | None = None):
    """Check if user is authenticated"""
    global drive_service
    
    if session_id:
        # Check session-based authentication
        creds = load_credentials_from_session(session_id)
        if creds:
            try:
                # Test if credentials are still valid
                test_service = build('drive', 'v3', credentials=creds)
                test_service.files().list(pageSize=1).execute()
                drive_service = test_service  # Update global service
                return {
                    "authenticated": True,
                    "message": "Session is valid and active",
                    "session_id": session_id
                }
            except Exception as e:
                # Credentials expired or invalid
                clear_session(session_id)
                return {
                    "authenticated": False,
                    "message": "Session expired or invalid",
                    "error": str(e)
                }
        else:
            return {
                "authenticated": False,
                "message": "No valid session found"
            }
    else:
        # Check global authentication
        if drive_service:
            try:
                # Test if service is still working
                drive_service.files().list(pageSize=1).execute()
                return {
                    "authenticated": True,
                    "message": "Connected to Google Drive"
                }
            except Exception as e:
                drive_service = None
                return {
                    "authenticated": False,
                    "message": "Connection lost",
                    "error": str(e)
                }
        else:
            return {
                "authenticated": False,
                "message": "Not authenticated"
            }

@app.post("/auth/disconnect")
def disconnect(session_id: str | None = None):
    """Disconnect from Google Drive and clear session"""
    global drive_service
    
    if session_id:
        clear_session(session_id)
    
    drive_service = None
    
    return {
        "status": "disconnected",
        "message": "Successfully disconnected from Google Drive"
    }

# ---------------------------
# 2Ô∏è‚É£ Index Drive Images
# ---------------------------
def crawl_drive_images(service, folder_id='root', folder_path='Root', max_images=999999):
    """Recursively crawl Google Drive and index images"""
    global image_index
    
    # Stop if we've already indexed enough images
    if len(image_index) >= max_images:
        print(f"üõë Reached limit of {max_images} images, stopping crawl")
        return
    
    print(f"üîç Crawling folder: {folder_path} (ID: {folder_id})")
    
    # Get images in current folder
    query = f"'{folder_id}' in parents and mimeType contains 'image/' and trashed=false"
    results = service.files().list(q=query, fields="files(id,name,parents)").execute()
    files = results.get('files', [])
    
    print(f"   üì∏ Found {len(files)} images in {folder_path}")

    for file in files:
        # Stop if we've reached the limit
        if len(image_index) >= max_images:
            print(f"üõë Reached limit of {max_images} images, stopping processing")
            break
            
        file_id = file['id']
        file_name = file['name']
        
        try:
            # Download image with SSL error handling
            request = service.files().get_media(fileId=file_id)
            try:
                file_content = request.execute()
                file_bytes = io.BytesIO(file_content)
            except Exception as ssl_error:
                if "SSL" in str(ssl_error) or "wrong version number" in str(ssl_error):
                    print(f"   ‚ö†Ô∏è SSL error downloading {file_name}, skipping...")
                    continue
                else:
                    raise ssl_error
            
            try:
                img = Image.open(file_bytes).convert("RGB")
            finally:
                # Ensure the BytesIO object is properly handled
                if hasattr(file_bytes, 'close'):
                    file_bytes.close()
            
            # CLIP embedding
            inputs = clip_processor(images=img, return_tensors="pt")
            inputs = {k: v.to(device) for k, v in inputs.items()}
            with torch.no_grad():
                image_features = clip_model.get_image_features(**inputs)
                embedding = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # Extract dominant colors
            colors = extract_dominant_colors(img)
            
            # YOLO object detection
            objects = detect_objects_yolo(img)
            
            # Store in index
            image_index[file_id] = {
                "name": file_name,
                "embedding": embedding.cpu(),
                "objects": objects,
                "colors": colors,
                "folder": folder_path
            }
            
            print(f"Indexed: {file_name} - Objects: {objects} - Colors: {colors}")
            
        except Exception as e:
            error_msg = str(e)
            if "SSL" in error_msg or "wrong version number" in error_msg:
                print(f"   ‚ö†Ô∏è SSL error with {file_name}, skipping...")
            elif "timeout" in error_msg.lower():
                print(f"   ‚è∞ Timeout downloading {file_name}, skipping...")
            else:
                print(f"   ‚ùå Failed to process {file_name}: {e}")

    # Crawl subfolders recursively
    query_folders = f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
    try:
        folder_results = service.files().list(q=query_folders, fields="files(id,name)").execute()
        subfolders = folder_results.get('files', [])
        
        print(f"   üìÅ Found {len(subfolders)} subfolders in {folder_path}")
        
        for folder in subfolders:
            print(f"   üìÇ Subfolder: {folder['name']} (ID: {folder['id']})")
        
        for folder in subfolders:
            new_folder_path = f"{folder_path}/{folder['name']}" if folder_path != 'Root' else folder['name']
            print(f"   üîÑ Recursively crawling: {folder['name']}")
            try:
                crawl_drive_images(service, folder_id=folder['id'], folder_path=new_folder_path, max_images=max_images)
            except Exception as e:
                print(f"   ‚ùå Error crawling folder {folder['name']}: {e}")
                print(f"   ‚è≠Ô∏è Continuing with next folder...")
                continue  # Continue with next folder instead of stopping
    except Exception as e:
        print(f"   ‚ùå Error getting subfolders: {e}")

@app.post("/index")
def index_drive():
    """Index all images in Google Drive"""
    if not drive_service:
        return {"error": "Not authenticated. Call /auth first."}
    
    global image_index
    image_index = {}  # Reset index
    
    try:
        # Start from the shared folder instead of root
        shared_folder_id = "11kSHWn47cQqeRhtlVQ-4Uask7jr2fqjW"
        print(f"üéØ Starting indexing from shared folder: {shared_folder_id}")
        print(f"üîó Folder URL: https://drive.google.com/drive/folders/{shared_folder_id}")
        print(f"üìä Indexing ALL images - NO LIMIT!")
        print(f"üîç This is MANUAL indexing - not automatic on connection")
        crawl_drive_images(drive_service, folder_id=shared_folder_id, folder_path="◊™◊ô◊ß◊ô◊ô◊™ ◊î ◊ë◊™◊ô◊ù", max_images=999999)
        return {
            "status": "Drive indexed successfully", 
            "total_images": len(image_index),
            "message": f"Indexed {len(image_index)} images with CLIP embeddings, YOLO objects, and color data"
        }
    except Exception as e:
        return {"error": f"Indexing failed: {str(e)}"}

# ---------------------------
# 3Ô∏è‚É£ Search Endpoint
# ---------------------------
class SearchRequest(BaseModel):
    query: str
    required_objects: list = []       # e.g., ["island"]
    required_colors: list = []        # e.g., [[128,0,128]] for purple
    top_k: int = 5

def search_images_internal(search_request):
    """Internal search function that returns results as list (not JSONResponse)"""
    if not image_index:
        return []
    
    # Translate Hebrew query to English for better CLIP understanding
    translated_query = translate_hebrew_query(search_request["query"])
    
    # Encode text query with CLIP
    text_inputs = clip_processor(text=[translated_query], return_tensors="pt", padding=True)
    text_inputs = {k: v.to(device) for k, v in text_inputs.items()}
    with torch.no_grad():
        text_features = clip_model.get_text_features(**text_inputs)
        text_emb = text_features / text_features.norm(dim=-1, keepdim=True)

    results = []
    for fid, data in image_index.items():
        # Semantic similarity score
        sim = (text_emb.cpu() @ data['embedding'].T).item()
        
        # Object filter score
        if search_request.get("required_objects"):
            obj_score = len(set(data['objects']) & set(search_request["required_objects"])) / max(1, len(search_request["required_objects"]))
        else:
            obj_score = 1.0
        
        # Color filter score
        if search_request.get("required_colors"):
            col_score = color_match_score(data['colors'], search_request["required_colors"])
        else:
            col_score = 1.0
        
        # Combined score using improved algorithm
        final_score = calculate_combined_score(sim, obj_score, col_score)
        
        results.append((fid, data['name'], final_score, data['objects'], data['colors'], sim, obj_score, col_score, data.get('folder', 'Root')))

    # Sort by score and return top results
    results.sort(key=lambda x: x[2], reverse=True)
    
    return [{
        "file_id": r[0],
        "name": r[1],
        "score": round(r[2], 4),
        "objects": r[3],
        "colors": r[4],
        "semantic_score": round(r[5], 4),
        "object_score": round(r[6], 4),
        "color_score": round(r[7], 4),
        "folder": r[8]
    } for r in results[:search_request.get("top_k", 6)]]

@app.post("/search")
def search_images(req: SearchRequest):
    """Search images using semantic similarity, object detection, and color matching"""
    if not image_index:
        return {"error": "No images indexed. Call /index first."}
    
    print(f"üîç Search request: {req.query}")
    print(f"üìä Total indexed images: {len(image_index)}")
    print(f"üìÇ Folders with images: {set(img.get('folder', 'Unknown') for img in image_index.values())}")
    
    # Translate Hebrew query to English for better CLIP understanding
    translated_query = translate_hebrew_query(req.query)
    
    # Encode text query with CLIP
    text_inputs = clip_processor(text=[translated_query], return_tensors="pt", padding=True)
    text_inputs = {k: v.to(device) for k, v in text_inputs.items()}
    with torch.no_grad():
        text_features = clip_model.get_text_features(**text_inputs)
        text_emb = text_features / text_features.norm(dim=-1, keepdim=True)

    results = []
    for fid, data in image_index.items():
        # Semantic similarity score
        sim = (text_emb.cpu() @ data['embedding'].T).item()
        
        # Object filter score
        if req.required_objects:
            obj_score = len(set(data['objects']) & set(req.required_objects)) / max(1, len(req.required_objects))
        else:
            obj_score = 1.0
        
        # Color filter score
        if req.required_colors:
            col_score = color_match_score(data['colors'], req.required_colors)
        else:
            col_score = 1.0
        
        # Combined score using improved algorithm
        final_score = calculate_combined_score(sim, obj_score, col_score)
        
        results.append((fid, data['name'], final_score, data['objects'], data['colors'], sim, obj_score, col_score, data.get('folder', 'Root')))

    # Sort by score and return top results
    results.sort(key=lambda x: x[2], reverse=True)
    
    return JSONResponse(content=[{
        "file_id": r[0],
        "name": r[1],
        "score": round(r[2], 4),
        "objects": r[3],
        "colors": r[4],
        "semantic_score": round(r[5], 4),
        "object_score": round(r[6], 4),
        "color_score": round(r[7], 4),
        "folder": r[8]
    } for r in results[:req.top_k]])

# ---------------------------
# 4Ô∏è‚É£ Parse Storyboard / PDF
# ---------------------------
def extract_text_from_pdf(content):
    """Extract text from PDF content"""
    try:
        import PyPDF2
        import io
        
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
        text = ""
        
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            except Exception as e:
                print(f"Error extracting text from page {page_num}: {e}")
                continue
        
        # If no text extracted, try alternative method
        if not text.strip():
            try:
                # Try extracting with different method
                for page in pdf_reader.pages:
                    if hasattr(page, 'get_contents'):
                        content_obj = page.get_contents()
                        if content_obj:
                            text += str(content_obj) + "\n"
            except Exception as e:
                print(f"Alternative PDF extraction failed: {e}")
        
        return text.strip() if text.strip() else "No text could be extracted from PDF"
        
    except ImportError:
        return "PyPDF2 not available for PDF text extraction"
    except Exception as e:
        return f"PDF extraction failed: {str(e)}"

def extract_requirements_from_text(text):
    """Extract design requirements from text using OpenAI API for better Hebrew analysis"""
    try:
        # Preprocess text to improve Hebrew parsing
        # Remove extra whitespace and normalize text
        text = ' '.join(text.split())
        
        # Use OpenAI API for better text analysis (new API format)
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """You are an expert in analyzing Hebrew and English text to extract comprehensive interior design and architectural requirements from storyboards and design documents.

CRITICAL: The text is in Hebrew. Pay special attention to Hebrew words and their meanings. Look for ALL categories mentioned in the text.

Extract the following comprehensive information from the text:

1. ROOM TYPES (◊°◊ï◊í◊ô ◊ó◊ì◊®◊ô◊ù): ◊°◊ú◊ï◊ü, ◊û◊ò◊ë◊ó, ◊§◊ô◊†◊™ ◊ê◊ï◊õ◊ú, ◊ó◊ì◊® ◊©◊ô◊†◊î ◊®◊ê◊©◊ô, ◊ó◊ì◊® ◊©◊ô◊†◊î ◊ô◊ú◊ì◊ô◊ù, ◊ó◊ì◊® ◊¢◊ë◊ï◊ì◊î, ◊ó◊ì◊® ◊®◊ó◊¶◊î ◊®◊ê◊©◊ô, ◊ó◊ì◊® ◊®◊ó◊¶◊î ◊ê◊ï◊®◊ó◊ô◊ù, ◊ó◊ì◊® ◊û◊©◊ó◊ß◊ô◊ù, ◊û◊®◊§◊°◊™ ◊°◊í◊ï◊®◊î, ◊ó◊¶◊®, ◊ë◊®◊ô◊õ◊î

2. STRUCTURE & SPACE PLANNING (◊û◊ë◊†◊î ◊ï◊™◊õ◊†◊ï◊ü ◊ó◊ú◊ú): ◊°◊ú◊ï◊ü ◊§◊™◊ï◊ó ◊ú◊û◊ò◊ë◊ó, ◊û◊ò◊ë◊ó ◊¢◊ù ◊ê◊ô, ◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î, ◊™◊ß◊®◊™ ◊¢◊•, ◊ó◊ú◊ï◊†◊ï◊™ ◊§◊†◊ï◊®◊û◊ô◊ô◊ù, ◊ó◊ì◊® ◊¢◊ù ◊í◊ú◊®◊ô◊î, ◊ì◊ú◊™◊ï◊™ ◊î◊ñ◊ñ◊î ◊û◊ñ◊õ◊ï◊õ◊ô◊™, ◊û◊°◊ì◊®◊ï◊ü ◊ê◊®◊ï◊ö, ◊ó◊ì◊® ◊¢◊ù ◊ß◊ô◊®◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™, ◊ß◊ô◊® ◊û◊ó◊ô◊¶◊î ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô

3. FLOORING TYPES (◊°◊ï◊í◊ô ◊®◊ô◊¶◊ï◊£): ◊§◊®◊ß◊ò ◊¢◊• ◊ò◊ë◊¢◊ô, ◊ë◊ò◊ï◊ü ◊û◊ï◊ó◊ú◊ß, ◊ê◊®◊ô◊ó◊ô ◊ß◊®◊û◊ô◊ß◊î, ◊®◊¶◊§◊™ ◊©◊ô◊©, ◊©◊ò◊ô◊ó◊ô◊ù ◊û◊ß◊ô◊® ◊ú◊ß◊ô◊®, ◊®◊¶◊§◊™ ◊ò◊®◊¶◊ï, ◊®◊¶◊§◊™ ◊ú◊ô◊†◊ï◊ú◊ô◊ê◊ï◊ù, ◊®◊¶◊§◊™ ◊¢◊• ◊ú◊û◊ô◊†◊¶◊ô◊î, ◊®◊¶◊§◊™ ◊ê◊§◊ï◊ß◊°◊ô, ◊û◊®◊¶◊§◊ï◊™ ◊û◊¶◊ï◊ô◊®◊ï◊™

4. DESIGN STYLES (◊°◊í◊†◊ï◊ü ◊¢◊ô◊¶◊ï◊ë◊ô): ◊û◊ï◊ì◊®◊†◊ô, ◊õ◊§◊®◊ô, ◊™◊¢◊©◊ô◊ô◊™◊ô, ◊°◊ß◊†◊ì◊ô◊†◊ë◊ô, ◊ê◊ß◊ú◊ß◊ò◊ô, ◊û◊ô◊†◊ô◊û◊ú◊ô◊°◊ò◊ô, ◊®◊ò◊®◊ï, ◊ï◊ô◊†◊ò◊í', ◊ë◊ï◊î◊ï ◊©◊ô◊ß, ◊¢◊ô◊¶◊ï◊ë ◊ê◊ï◊®◊ë◊†◊ô

5. FINISHING MATERIALS (◊ó◊ï◊û◊®◊ô ◊í◊û◊®): ◊ß◊ô◊®◊ï◊™ ◊ë◊ò◊ï◊ü ◊ó◊©◊ï◊£, ◊¢◊• ◊û◊ú◊ê, ◊ñ◊õ◊ï◊õ◊ô◊™ ◊û◊ó◊ï◊°◊û◊™, ◊§◊ú◊ô◊ñ ◊û◊ë◊®◊ô◊ß, ◊ë◊®◊ñ◊ú ◊©◊ó◊ï◊®, ◊¢◊ï◊® ◊ê◊ô◊õ◊ï◊™◊ô, ◊ê◊®◊ô◊ó◊ô◊ù ◊û◊ê◊ë◊ü ◊ò◊ë◊¢◊ô◊™, ◊ò◊ô◊ó ◊û◊ô◊†◊®◊ú◊ô, ◊ò◊§◊ò◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù, ◊û◊™◊õ◊™ ◊ê◊ú◊ï◊û◊ô◊†◊ô◊ï◊ù

6. CEILINGS (◊™◊ß◊®◊ï◊™): ◊™◊ß◊®◊î ◊¢◊ù ◊ß◊ï◊®◊ï◊™ ◊¢◊•, ◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î, ◊™◊ß◊®◊î ◊†◊û◊ï◊õ◊î, ◊™◊ß◊®◊î ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊†◊°◊™◊®◊™, ◊™◊ß◊®◊™ ◊í◊ë◊° ◊û◊¢◊ï◊¶◊ë◊™, ◊™◊ß◊®◊î ◊û◊©◊ï◊§◊¢◊™, ◊™◊ß◊®◊î ◊û◊ß◊ï◊û◊®◊™, ◊™◊ß◊®◊™ ◊ñ◊õ◊ï◊õ◊ô◊™, ◊™◊ß◊®◊î ◊¢◊ù ◊ó◊ú◊ï◊ü ◊í◊í, ◊™◊ß◊®◊î ◊ê◊ß◊ï◊°◊ò◊ô◊™

7. OPENINGS & TRANSITIONS (◊§◊™◊ó◊ô◊ù ◊ï◊û◊¢◊ë◊®◊ô◊ù): ◊ó◊ú◊ï◊†◊ï◊™ ◊ß◊ô◊®-◊ú◊ß◊ô◊®, ◊ì◊ú◊™◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™, ◊ó◊ú◊ï◊†◊ï◊™ ◊ë◊ú◊í◊ô◊ô◊ù, ◊§◊™◊ó◊ô◊ù ◊¢◊í◊ï◊ú◊ô◊ù, ◊ì◊ú◊™◊ï◊™ ◊¢◊• ◊û◊ú◊ê, ◊™◊®◊ô◊°◊ô◊ù ◊û◊¢◊•, ◊ó◊ú◊ï◊†◊ï◊™ ◊¢◊ù ◊û◊°◊í◊®◊™ ◊û◊™◊õ◊™, ◊ó◊ú◊ï◊†◊ï◊™ ◊í◊í, ◊ì◊ú◊™◊ï◊™ ◊§◊ú◊ì◊î, ◊§◊™◊ó◊ô ◊™◊ê◊ï◊®◊î ◊ë◊™◊ß◊®◊î

8. FLOORS & STRUCTURE (◊ß◊ï◊û◊ï◊™ ◊ï◊û◊ë◊†◊î): ◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊™ ◊ß◊®◊ß◊¢, ◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊î ◊¢◊ú◊ô◊ï◊†◊î, ◊ì◊ï◊§◊ú◊ß◊°, ◊§◊†◊ò◊î◊ê◊ï◊ñ, ◊ú◊ï◊§◊ò, ◊ï◊ô◊ú◊î ◊¢◊ô◊®◊ï◊†◊ô◊™, ◊ß◊ï◊ò◊í' ◊§◊®◊ë◊®◊ô, ◊ë◊ô◊™ ◊ú◊©◊ô◊û◊ï◊®, ◊û◊ë◊†◊î ◊™◊¢◊©◊ô◊ô◊™◊ô, ◊û◊ë◊†◊î ◊û◊ï◊ì◊®◊†◊ô

9. LIGHTING (◊™◊ê◊ï◊®◊î): ◊™◊ê◊ï◊®◊î ◊ò◊ë◊¢◊ô◊™, ◊™◊ê◊ï◊®◊™ ◊ú◊ì ◊†◊°◊™◊®◊™, ◊û◊†◊ï◊®◊ï◊™ ◊™◊ß◊®◊î ◊û◊¢◊ï◊¶◊ë◊ï◊™, ◊û◊†◊ï◊®◊ï◊™ ◊ß◊ô◊®, ◊™◊ê◊ï◊®◊™ ◊ê◊ï◊ï◊ô◊®◊î, ◊™◊ê◊ï◊®◊î ◊û◊™◊õ◊ï◊ï◊†◊†◊™, ◊™◊ê◊ï◊®◊™ ◊§◊ú◊ï◊®◊°◊†◊ò, ◊†◊ë◊®◊©◊ï◊™ ◊ß◊®◊ô◊°◊ò◊ú, ◊™◊ê◊ï◊®◊™ ◊©◊ï◊ú◊ó◊ü, ◊™◊ê◊ï◊®◊™ ◊ó◊ï◊•

10. FURNITURE (◊®◊ô◊î◊ï◊ò): ◊°◊§◊ï◊™ ◊¢◊ï◊®, ◊©◊ï◊ú◊ó◊ü ◊ê◊ï◊õ◊ú ◊û◊¢◊• ◊û◊ú◊ê, ◊©◊ï◊ú◊ó◊ü ◊ß◊§◊î, ◊õ◊ï◊®◊°◊ê◊ï◊™ ◊ë◊ì, ◊õ◊°◊ê◊ï◊™ ◊ë◊®, ◊û◊ô◊ò◊î ◊ñ◊ï◊í◊ô◊™, ◊ê◊®◊ï◊ü ◊ß◊ô◊®, ◊û◊ì◊§◊ô◊ù ◊§◊™◊ï◊ó◊ô◊ù, ◊§◊ô◊†◊™ ◊ô◊©◊ô◊ë◊î, ◊©◊ï◊ú◊ó◊ü ◊¢◊ë◊ï◊ì◊î

11. WALLS (◊ß◊ô◊®◊ï◊™): ◊ß◊ô◊® ◊ú◊ë◊†◊ô◊ù ◊ó◊©◊ï◊£, ◊ß◊ô◊® ◊¢◊ù ◊ò◊§◊ò◊ô◊ù, ◊ß◊ô◊® ◊¶◊ë◊¢◊ï◊†◊ô, ◊ß◊ô◊® ◊¢◊ù ◊ê◊®◊ô◊ó◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù, ◊ß◊ô◊® ◊¢◊ù ◊™◊û◊ï◊†◊ï◊™ ◊ê◊û◊†◊ï◊™, ◊ß◊ô◊® ◊¢◊ù ◊û◊®◊ê◊î ◊í◊ì◊ï◊ú◊î, ◊ß◊ô◊® ◊û◊¢◊• ◊ò◊ë◊¢◊ô, ◊ß◊ô◊® ◊¢◊ù ◊ì◊ú◊™◊ï◊™ ◊†◊°◊™◊®◊ï◊™, ◊ß◊ô◊® ◊í◊ë◊° ◊ê◊ß◊ï◊°◊ò◊ô, ◊ß◊ô◊® ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊§◊†◊ô◊û◊ô◊™

12. YARD & GARDEN (◊ó◊¶◊® ◊ï◊í◊ô◊†◊î): ◊í◊ô◊†◊î ◊§◊®◊ò◊ô◊™, ◊í◊ô◊†◊î ◊ê◊ï◊®◊ë◊†◊ô◊™, ◊û◊®◊§◊°◊™ ◊™◊ú◊ï◊ô◊î, ◊ó◊¶◊® ◊§◊†◊ô◊û◊ô◊™, ◊í◊í ◊ô◊®◊ï◊ß, ◊ì◊ß ◊¢◊•, ◊ê◊ñ◊ï◊® ◊ô◊©◊ô◊ë◊î ◊ó◊ô◊¶◊ï◊†◊ô, ◊ë◊®◊ô◊õ◊™ ◊©◊ó◊ô◊ô◊î ◊§◊®◊ò◊ô◊™, ◊í◊ô◊†◊î ◊ô◊ù-◊™◊ô◊õ◊ï◊†◊ô◊™, ◊©◊ë◊ô◊ú◊ô ◊í◊ô◊†◊î ◊û◊®◊ï◊¶◊§◊ô◊ù

13. DECORATIVE ACCESSORIES (◊ê◊ß◊°◊°◊ï◊®◊ô◊ñ ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù): ◊õ◊®◊ô◊ï◊™ ◊†◊ï◊ô, ◊©◊ò◊ô◊ó◊ô◊ù ◊û◊¢◊ï◊¶◊ë◊ô◊ù, ◊™◊û◊ï◊†◊ï◊™ ◊ß◊ô◊®, ◊ï◊ô◊ú◊ï◊†◊ï◊™ ◊ë◊ì, ◊§◊°◊ú◊ô◊ù ◊û◊ï◊ì◊®◊†◊ô◊ô◊ù, ◊†◊®◊ï◊™ ◊®◊ô◊ó◊†◊ô◊ô◊ù, ◊ê◊í◊®◊ò◊ú◊ô◊ù ◊ñ◊õ◊ï◊õ◊ô◊™, ◊û◊®◊ê◊ï◊™ ◊û◊¢◊ï◊¶◊ë◊ï◊™, ◊õ◊ú◊ô ◊ó◊®◊°, ◊¢◊¶◊ô◊¶◊ô◊ù ◊ï◊¶◊û◊ó◊ô◊ù ◊ô◊®◊ï◊ß◊ô◊ù

14. COLOR PALETTE (◊¶◊ë◊¢◊ï◊†◊ô◊ï◊™): ◊û◊ï◊†◊ï◊õ◊®◊ï◊û◊ò◊ô, ◊í◊ï◊ï◊†◊ô ◊§◊°◊ò◊ú, ◊¶◊ë◊¢◊ô◊ù ◊†◊ô◊ò◊®◊ú◊ô◊ô◊ù, ◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ó◊û◊î, ◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ß◊®◊î, ◊í◊ï◊ï◊†◊ô◊ù ◊õ◊î◊ô◊ù ◊ï◊¢◊©◊ô◊®◊ô◊ù, ◊ß◊ô◊®◊ï◊™ ◊¶◊ë◊¢◊ï◊†◊ô◊ô◊ù, ◊†◊ô◊í◊ï◊ì◊ô ◊©◊ó◊ï◊® ◊ï◊ú◊ë◊ü, ◊¶◊ë◊¢◊ô ◊ê◊ì◊û◊î, ◊í◊ï◊ï◊†◊ô◊ù ◊ë◊î◊ô◊®◊ô◊ù ◊ï◊û◊ê◊ï◊ï◊®◊®◊ô◊ù

15. SPACE CHARACTER (◊ê◊ï◊§◊ô ◊î◊ó◊ú◊ú): ◊ó◊ú◊ú ◊§◊™◊ï◊ó, ◊ó◊ú◊ú ◊®◊ë-◊™◊õ◊ú◊ô◊™◊ô, ◊ó◊ú◊ú ◊ê◊ô◊†◊ò◊ô◊û◊ô, ◊ó◊ú◊ú ◊¢◊ù ◊ñ◊®◊ô◊û◊î ◊ò◊ë◊¢◊ô◊™, ◊ó◊ú◊ú ◊®◊©◊û◊ô, ◊ó◊ú◊ú ◊û◊ó◊ï◊ú◊ß ◊ë◊ê◊ú◊í◊†◊ò◊ô◊ï◊™, ◊ó◊ú◊ú ◊¢◊ù ◊†◊ï◊£ ◊§◊™◊ï◊ó, ◊ó◊ú◊ú ◊û◊®◊ï◊ï◊ó, ◊ó◊ú◊ú ◊ß◊ï◊û◊§◊ß◊ò◊ô, ◊ó◊ú◊ú ◊û◊ï◊ê◊® ◊î◊ô◊ò◊ë

IMPORTANT: Look for specific locations mentioned like "◊®◊ó◊ï◊ë ◊û◊®◊õ◊ñ◊ô ◊ë◊¢◊ô◊®", "◊ì◊ô◊®◊î ◊û◊ï◊ì◊®◊†◊ô◊™", "◊ó◊ï◊£ ◊ô◊ù", "◊í◊í ◊¢◊ô◊®◊ï◊†◊ô", etc. Be comprehensive and identify ALL relevant categories from the text.

Return ONLY a JSON object with this exact structure:
{
    "location": "primary location or null",
    "style": ["list", "of", "styles"],
    "required_objects": ["list", "of", "objects"],
    "required_colors": ["list", "of", "colors"]
}

If no requirements are found, return empty arrays and null for location."""
                },
                {
                    "role": "user",
                    "content": f"Analyze this text and extract design requirements:\n\n{text}"
                }
            ],
            max_tokens=500,
            temperature=0.1
        )
        
        # Parse the JSON response
        import json
        result = json.loads(response.choices[0].message.content)
        
        # Validate the response structure
        if not isinstance(result, dict):
            raise ValueError("Invalid response format")
        
        # Ensure all required fields exist
        return {
            "location": result.get("location"),
            "style": result.get("style", []),
            "required_objects": result.get("required_objects", []),
            "required_colors": result.get("required_colors", [])
        }
        
    except Exception as e:
        print(f"OpenAI API error: {e}")
        # Fallback to simple keyword matching
        return extract_requirements_fallback(text)

def extract_requirements_fallback(text):
    """Fallback method using comprehensive keyword matching for all 15 categories"""
    text_lower = text.lower()
    
    # 1. Room Types (◊°◊ï◊í◊ô ◊ó◊ì◊®◊ô◊ù)
    locations = {
        "kitchen": ["kitchen", "cooking", "cook", "stove", "sink", "island", "◊û◊ò◊ë◊ó", "◊û◊ò◊ë◊ó◊ï◊ü", "◊õ◊ô◊®◊ô◊ô◊ù", "◊™◊†◊ï◊®", "◊õ◊ô◊ï◊®", "◊û◊ò◊ë◊ó ◊§◊™◊ï◊ó"],
        "bedroom": ["bedroom", "bed", "sleep", "master", "guest", "◊ó◊ì◊® ◊©◊ô◊†◊î", "◊ó◊ì◊® ◊©◊ô◊†◊î ◊®◊ê◊©◊ô", "◊ó◊ì◊® ◊©◊ô◊†◊î ◊ô◊ú◊ì◊ô◊ù", "◊û◊ô◊ò◊î"],
        "living room": ["living room", "lounge", "sitting", "tv", "sofa", "◊°◊ú◊ï◊ü", "◊ó◊ì◊® ◊û◊í◊ï◊®◊ô◊ù", "◊°◊ú◊ï◊ü ◊û◊ï◊ì◊®◊†◊ô"],
        "dining room": ["dining", "dinner", "table", "eat", "◊§◊ô◊†◊™ ◊ê◊ï◊õ◊ú", "◊ó◊ì◊® ◊ê◊ï◊õ◊ú"],
        "office": ["office", "study", "work", "desk", "computer", "◊û◊©◊®◊ì", "◊ó◊ì◊® ◊¢◊ë◊ï◊ì◊î"],
        "bathroom": ["bathroom", "bath", "shower", "toilet", "vanity", "◊©◊ô◊®◊ï◊™◊ô◊ù", "◊ê◊û◊ë◊ò◊ô◊î", "◊ó◊ì◊® ◊®◊ó◊¶◊î ◊®◊ê◊©◊ô", "◊ó◊ì◊® ◊®◊ó◊¶◊î ◊ê◊ï◊®◊ó◊ô◊ù"],
        "nursery": ["nursery", "baby", "child", "kids", "crib", "◊ó◊ì◊® ◊ô◊ú◊ì◊ô◊ù", "◊ó◊ì◊® ◊™◊ô◊†◊ï◊ß", "◊ó◊ì◊® ◊û◊©◊ó◊ß◊ô◊ù"],
        "garden": ["garden", "yard", "◊í◊ü", "◊í◊ô◊†◊î", "◊ó◊¶◊®", "◊ë◊®◊ô◊õ◊î"],
        "balcony": ["balcony", "terrace", "◊û◊®◊§◊°◊™", "◊û◊®◊§◊°◊™ ◊°◊í◊ï◊®◊î"],
        "rooftop": ["rooftop", "roof", "◊í◊í", "◊í◊í ◊¢◊ô◊®◊ï◊†◊ô", "◊í◊í ◊¢◊ô◊®◊ï◊†◊ô ◊¢◊ù ◊†◊ï◊£"],
        "street": ["street", "◊®◊ó◊ï◊ë", "◊®◊ó◊ï◊ë ◊û◊®◊õ◊ñ◊ô", "◊®◊ó◊ï◊ë ◊ê◊ï◊®◊ë◊†◊ô", "◊®◊ó◊ï◊ë ◊ê◊ï◊®◊ë◊†◊ô ◊©◊ï◊ß◊ß"],
        "beach": ["beach", "sea", "◊ó◊ï◊£", "◊ó◊ï◊£ ◊ô◊ù", "◊ô◊ù ◊î◊™◊ô◊õ◊ï◊ü", "◊ó◊ï◊£ ◊ô◊ù ◊ë◊©◊¢◊™ ◊©◊ß◊ô◊¢◊î"],
        "city": ["city", "◊¢◊ô◊®", "◊™◊ú ◊ê◊ë◊ô◊ë", "◊ô◊®◊ï◊©◊ú◊ô◊ù", "◊ì◊ô◊®◊î ◊û◊ï◊ì◊®◊†◊ô◊™"],
        "apartment": ["apartment", "◊ì◊ô◊®◊î", "◊ì◊ô◊®◊î ◊û◊ï◊ì◊®◊†◊ô◊™", "◊§◊†◊ô◊ù ◊ë◊ô◊™"]
    }
    
    detected_location = None
    for location, keywords in locations.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_location = location
            break
    
    # 2. Structure & Space Planning (◊û◊ë◊†◊î ◊ï◊™◊õ◊†◊ï◊ü ◊ó◊ú◊ú)
    structure_keywords = [
        "◊°◊ú◊ï◊ü ◊§◊™◊ï◊ó ◊ú◊û◊ò◊ë◊ó", "◊û◊ò◊ë◊ó ◊¢◊ù ◊ê◊ô", "◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î", "◊™◊ß◊®◊™ ◊¢◊•", "◊ó◊ú◊ï◊†◊ï◊™ ◊§◊†◊ï◊®◊û◊ô◊ô◊ù",
        "◊ó◊ì◊® ◊¢◊ù ◊í◊ú◊®◊ô◊î", "◊ì◊ú◊™◊ï◊™ ◊î◊ñ◊ñ◊î ◊û◊ñ◊õ◊ï◊õ◊ô◊™", "◊û◊°◊ì◊®◊ï◊ü ◊ê◊®◊ï◊ö", "◊ó◊ì◊® ◊¢◊ù ◊ß◊ô◊®◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™", "◊ß◊ô◊® ◊û◊ó◊ô◊¶◊î ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô"
    ]
    
    # 3. Flooring Types (◊°◊ï◊í◊ô ◊®◊ô◊¶◊ï◊£)
    flooring_keywords = [
        "◊§◊®◊ß◊ò ◊¢◊• ◊ò◊ë◊¢◊ô", "◊ë◊ò◊ï◊ü ◊û◊ï◊ó◊ú◊ß", "◊ê◊®◊ô◊ó◊ô ◊ß◊®◊û◊ô◊ß◊î", "◊®◊¶◊§◊™ ◊©◊ô◊©", "◊©◊ò◊ô◊ó◊ô◊ù ◊û◊ß◊ô◊® ◊ú◊ß◊ô◊®",
        "◊®◊¶◊§◊™ ◊ò◊®◊¶◊ï", "◊®◊¶◊§◊™ ◊ú◊ô◊†◊ï◊ú◊ô◊ê◊ï◊ù", "◊®◊¶◊§◊™ ◊¢◊• ◊ú◊û◊ô◊†◊¶◊ô◊î", "◊®◊¶◊§◊™ ◊ê◊§◊ï◊ß◊°◊ô", "◊û◊®◊¶◊§◊ï◊™ ◊û◊¶◊ï◊ô◊®◊ï◊™"
    ]
    
    # 4. Design Styles (◊°◊í◊†◊ï◊ü ◊¢◊ô◊¶◊ï◊ë◊ô)
    styles = {
        "modern": ["modern", "contemporary", "sleek", "minimalist", "◊û◊ï◊ì◊®◊†◊ô", "◊û◊ï◊ì◊®◊†◊ô◊™"],
        "rustic": ["rustic", "farmhouse", "country", "wooden", "◊õ◊§◊®◊ô", "◊õ◊§◊®◊ô◊™"],
        "industrial": ["industrial", "metal", "concrete", "exposed", "◊™◊¢◊©◊ô◊ô◊™◊ô", "◊™◊¢◊©◊ô◊ô◊™◊ô◊™"],
        "scandinavian": ["scandinavian", "scandi", "nordic", "hygge", "◊°◊ß◊†◊ì◊ô◊†◊ë◊ô", "◊°◊ß◊†◊ì◊ô◊†◊ë◊ô◊™"],
        "eclectic": ["eclectic", "mixed", "varied", "◊ê◊ß◊ú◊ß◊ò◊ô", "◊ê◊ß◊ú◊ß◊ò◊ô◊™"],
        "minimalist": ["minimalist", "minimal", "clean", "simple", "◊û◊ô◊†◊ô◊û◊ú◊ô◊°◊ò◊ô", "◊û◊ô◊†◊ô◊û◊ú◊ô◊°◊ò◊ô◊™"],
        "retro": ["retro", "vintage", "classic", "◊®◊ò◊®◊ï", "◊ï◊ô◊†◊ò◊í"],
        "boho chic": ["bohemian", "boho", "vibrant", "◊ë◊ï◊î◊ï ◊©◊ô◊ß"],
        "urban design": ["urban", "city", "metropolitan", "◊¢◊ô◊¶◊ï◊ë ◊ê◊ï◊®◊ë◊†◊ô"]
    }
    
    # 5. Finishing Materials (◊ó◊ï◊û◊®◊ô ◊í◊û◊®)
    materials_keywords = [
        "◊ß◊ô◊®◊ï◊™ ◊ë◊ò◊ï◊ü ◊ó◊©◊ï◊£", "◊¢◊• ◊û◊ú◊ê", "◊ñ◊õ◊ï◊õ◊ô◊™ ◊û◊ó◊ï◊°◊û◊™", "◊§◊ú◊ô◊ñ ◊û◊ë◊®◊ô◊ß", "◊ë◊®◊ñ◊ú ◊©◊ó◊ï◊®",
        "◊¢◊ï◊® ◊ê◊ô◊õ◊ï◊™◊ô", "◊ê◊®◊ô◊ó◊ô◊ù ◊û◊ê◊ë◊ü ◊ò◊ë◊¢◊ô◊™", "◊ò◊ô◊ó ◊û◊ô◊†◊®◊ú◊ô", "◊ò◊§◊ò◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù", "◊û◊™◊õ◊™ ◊ê◊ú◊ï◊û◊ô◊†◊ô◊ï◊ù"
    ]
    
    # 6. Ceilings (◊™◊ß◊®◊ï◊™)
    ceiling_keywords = [
        "◊™◊ß◊®◊î ◊¢◊ù ◊ß◊ï◊®◊ï◊™ ◊¢◊•", "◊™◊ß◊®◊î ◊í◊ë◊ï◊î◊î", "◊™◊ß◊®◊î ◊†◊û◊ï◊õ◊î", "◊™◊ß◊®◊î ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊†◊°◊™◊®◊™", "◊™◊ß◊®◊™ ◊í◊ë◊° ◊û◊¢◊ï◊¶◊ë◊™",
        "◊™◊ß◊®◊î ◊û◊©◊ï◊§◊¢◊™", "◊™◊ß◊®◊î ◊û◊ß◊ï◊û◊®◊™", "◊™◊ß◊®◊™ ◊ñ◊õ◊ï◊õ◊ô◊™", "◊™◊ß◊®◊î ◊¢◊ù ◊ó◊ú◊ï◊ü ◊í◊í", "◊™◊ß◊®◊î ◊ê◊ß◊ï◊°◊ò◊ô◊™"
    ]
    
    # 7. Openings & Transitions (◊§◊™◊ó◊ô◊ù ◊ï◊û◊¢◊ë◊®◊ô◊ù)
    openings_keywords = [
        "◊ó◊ú◊ï◊†◊ï◊™ ◊ß◊ô◊®-◊ú◊ß◊ô◊®", "◊ì◊ú◊™◊ï◊™ ◊ñ◊õ◊ï◊õ◊ô◊™", "◊ó◊ú◊ï◊†◊ï◊™ ◊ë◊ú◊í◊ô◊ô◊ù", "◊§◊™◊ó◊ô◊ù ◊¢◊í◊ï◊ú◊ô◊ù", "◊ì◊ú◊™◊ï◊™ ◊¢◊• ◊û◊ú◊ê",
        "◊™◊®◊ô◊°◊ô◊ù ◊û◊¢◊•", "◊ó◊ú◊ï◊†◊ï◊™ ◊¢◊ù ◊û◊°◊í◊®◊™ ◊û◊™◊õ◊™", "◊ó◊ú◊ï◊†◊ï◊™ ◊í◊í", "◊ì◊ú◊™◊ï◊™ ◊§◊ú◊ì◊î", "◊§◊™◊ó◊ô ◊™◊ê◊ï◊®◊î ◊ë◊™◊ß◊®◊î"
    ]
    
    # 8. Floors & Structure (◊ß◊ï◊û◊ï◊™ ◊ï◊û◊ë◊†◊î)
    structure_types = [
        "◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊™ ◊ß◊®◊ß◊¢", "◊ì◊ô◊®◊î ◊ë◊ß◊ï◊û◊î ◊¢◊ú◊ô◊ï◊†◊î", "◊ì◊ï◊§◊ú◊ß◊°", "◊†◊ò◊î◊ê◊ï◊ñ", "◊ú◊ï◊§◊ò",
        "◊ï◊ô◊ú◊î ◊¢◊ô◊®◊ï◊†◊ô◊™", "◊ß◊ï◊ò◊í' ◊§◊®◊ë◊®◊ô", "◊ë◊ô◊™ ◊ú◊©◊ô◊û◊ï◊®", "◊û◊ë◊†◊î ◊™◊¢◊©◊ô◊ô◊™◊ô", "◊û◊ë◊†◊î ◊û◊ï◊ì◊®◊†◊ô"
    ]
    
    # 9. Lighting (◊™◊ê◊ï◊®◊î)
    lighting_keywords = [
        "◊™◊ê◊ï◊®◊î ◊ò◊ë◊¢◊ô◊™", "◊™◊ê◊ï◊®◊™ ◊ú◊ì ◊†◊°◊™◊®◊™", "◊û◊†◊ï◊®◊ï◊™ ◊™◊ß◊®◊î ◊û◊¢◊ï◊¶◊ë◊ï◊™", "◊û◊†◊ï◊®◊ï◊™ ◊ß◊ô◊®", "◊™◊ê◊ï◊®◊™ ◊ê◊ï◊ï◊ô◊®◊î",
        "◊™◊ê◊ï◊®◊î ◊û◊™◊õ◊ï◊ï◊†◊†◊™", "◊™◊ê◊ï◊®◊™ ◊§◊ú◊ï◊®◊°◊†◊ò", "◊†◊ë◊®◊©◊ï◊™ ◊ß◊®◊ô◊°◊ò◊ú", "◊™◊ê◊ï◊®◊™ ◊©◊ï◊ú◊ó◊ü", "◊™◊ê◊ï◊®◊™ ◊ó◊ï◊•"
    ]
    
    # 10. Furniture (◊®◊ô◊î◊ï◊ò)
    furniture_keywords = [
        "◊°◊§◊ï◊™ ◊¢◊ï◊®", "◊©◊ï◊ú◊ó◊ü ◊ê◊ï◊õ◊ú ◊û◊¢◊• ◊û◊ú◊ê", "◊©◊ï◊ú◊ó◊ü ◊ß◊§◊î", "◊õ◊ï◊®◊°◊ê◊ï◊™ ◊ë◊ì", "◊õ◊°◊ê◊ï◊™ ◊ë◊®",
        "◊û◊ô◊ò◊î ◊ñ◊ï◊í◊ô◊™", "◊ê◊®◊ï◊ü ◊ß◊ô◊®", "◊û◊ì◊§◊ô◊ù ◊§◊™◊ï◊ó◊ô◊ù", "◊§◊ô◊†◊™ ◊ô◊©◊ô◊ë◊î", "◊©◊ï◊ú◊ó◊ü ◊¢◊ë◊ï◊ì◊î"
    ]
    
    # 11. Walls (◊ß◊ô◊®◊ï◊™)
    wall_keywords = [
        "◊ß◊ô◊® ◊ú◊ë◊†◊ô◊ù ◊ó◊©◊ï◊£", "◊ß◊ô◊® ◊¢◊ù ◊ò◊§◊ò◊ô◊ù", "◊ß◊ô◊® ◊¶◊ë◊¢◊ï◊†◊ô", "◊ß◊ô◊® ◊¢◊ù ◊ê◊®◊ô◊ó◊ô◊ù ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù", "◊ß◊ô◊® ◊¢◊ù ◊™◊û◊ï◊†◊ï◊™ ◊ê◊û◊†◊ï◊™",
        "◊ß◊ô◊® ◊¢◊ù ◊û◊®◊ê◊î ◊í◊ì◊ï◊ú◊î", "◊ß◊ô◊® ◊û◊¢◊• ◊ò◊ë◊¢◊ô", "◊ß◊ô◊® ◊¢◊ù ◊ì◊ú◊™◊ï◊™ ◊†◊°◊™◊®◊ï◊™", "◊ß◊ô◊® ◊í◊ë◊° ◊ê◊ß◊ï◊°◊ò◊ô", "◊ß◊ô◊® ◊¢◊ù ◊™◊ê◊ï◊®◊î ◊§◊†◊ô◊û◊ô◊™"
    ]
    
    # 12. Yard & Garden (◊ó◊¶◊® ◊ï◊í◊ô◊†◊î)
    garden_keywords = [
        "◊í◊ô◊†◊î ◊§◊®◊ò◊ô◊™", "◊í◊ô◊†◊î ◊ê◊ï◊®◊ë◊†◊ô◊™", "◊û◊®◊§◊°◊™ ◊™◊ú◊ï◊ô◊î", "◊ó◊¶◊® ◊§◊†◊ô◊û◊ô◊™", "◊í◊í ◊ô◊®◊ï◊ß",
        "◊ì◊ß ◊¢◊•", "◊ê◊ñ◊ï◊® ◊ô◊©◊ô◊ë◊î ◊ó◊ô◊¶◊ï◊†◊ô", "◊ë◊®◊ô◊õ◊™ ◊©◊ó◊ô◊ô◊î ◊§◊®◊ò◊ô◊™", "◊í◊ô◊†◊î ◊ô◊ù-◊™◊ô◊õ◊ï◊†◊ô◊™", "◊©◊ë◊ô◊ú◊ô ◊í◊ô◊†◊î ◊û◊®◊ï◊¶◊§◊ô◊ù"
    ]
    
    # 13. Decorative Accessories (◊ê◊ß◊°◊°◊ï◊®◊ô◊ñ ◊ì◊ß◊ï◊®◊ò◊ô◊ë◊ô◊ô◊ù)
    accessories_keywords = [
        "◊õ◊®◊ô◊ï◊™ ◊†◊ï◊ô", "◊©◊ò◊ô◊ó◊ô◊ù ◊û◊¢◊ï◊¶◊ë◊ô◊ù", "◊™◊û◊ï◊†◊ï◊™ ◊ß◊ô◊®", "◊ï◊ô◊ú◊ï◊†◊ï◊™ ◊ë◊ì", "◊§◊°◊ú◊ô◊ù ◊û◊ï◊ì◊®◊†◊ô◊ô◊ù",
        "◊†◊®◊ï◊™ ◊®◊ô◊ó◊†◊ô◊ô◊ù", "◊ê◊í◊®◊ò◊ú◊ô◊ù ◊ñ◊õ◊ï◊õ◊ô◊™", "◊û◊®◊ê◊ï◊™ ◊û◊¢◊ï◊¶◊ë◊ï◊™", "◊õ◊ú◊ô ◊ó◊®◊°", "◊¢◊¶◊ô◊¶◊ô◊ù ◊ï◊¶◊û◊ó◊ô◊ù ◊ô◊®◊ï◊ß◊ô◊ù"
    ]
    
    # 14. Color Palette (◊¶◊ë◊¢◊ï◊†◊ô◊ï◊™)
    color_keywords = [
        "◊û◊ï◊†◊ï◊õ◊®◊ï◊û◊ò◊ô", "◊í◊ï◊ï◊†◊ô ◊§◊°◊ò◊ú", "◊¶◊ë◊¢◊ô◊ù ◊†◊ô◊ò◊®◊ú◊ô◊ô◊ù", "◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ó◊û◊î", "◊§◊ú◊ò◊™ ◊¶◊ë◊¢◊ô◊ù ◊ß◊®◊î",
        "◊í◊ï◊ï◊†◊ô◊ù ◊õ◊î◊ô◊ù ◊ï◊¢◊©◊ô◊®◊ô◊ù", "◊ß◊ô◊®◊ï◊™ ◊¶◊ë◊¢◊ï◊†◊ô◊ô◊ù", "◊†◊ô◊í◊ï◊ì◊ô ◊©◊ó◊ï◊® ◊ï◊ú◊ë◊ü", "◊¶◊ë◊¢◊ô ◊ê◊ì◊û◊î", "◊í◊ï◊ï◊†◊ô◊ù ◊ë◊î◊ô◊®◊ô◊ù ◊ï◊û◊ê◊ï◊ï◊®◊®◊ô◊ù"
    ]
    
    # 15. Space Character (◊ê◊ï◊§◊ô ◊î◊ó◊ú◊ú)
    space_character_keywords = [
        "◊ó◊ú◊ú ◊§◊™◊ï◊ó", "◊ó◊ú◊ú ◊®◊ë-◊™◊õ◊ú◊ô◊™◊ô", "◊ó◊ú◊ú ◊ê◊ô◊†◊ò◊ô◊û◊ô", "◊ó◊ú◊ú ◊¢◊ù ◊ñ◊®◊ô◊û◊î ◊ò◊ë◊¢◊ô◊™", "◊ó◊ú◊ú ◊®◊©◊û◊ô",
        "◊ó◊ú◊ú ◊û◊ó◊ï◊ú◊ß ◊ë◊ê◊ú◊í◊†◊ò◊ô◊ï◊™", "◊ó◊ú◊ú ◊¢◊ù ◊†◊ï◊£ ◊§◊™◊ï◊ó", "◊ó◊ú◊ú ◊û◊®◊ï◊ï◊ó", "◊ó◊ú◊ú ◊ß◊ï◊û◊§◊ß◊ò◊ô", "◊ó◊ú◊ú ◊û◊ï◊ê◊® ◊î◊ô◊ò◊ë"
    ]
    
    detected_styles = []
    for style, keywords in styles.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_styles.append(style)
    
    # Detect all other categories
    detected_objects = []
    detected_colors = []
    
    # Check for structure keywords
    for keyword in structure_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for flooring keywords
    for keyword in flooring_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for materials keywords
    for keyword in materials_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for ceiling keywords
    for keyword in ceiling_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for openings keywords
    for keyword in openings_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for structure types
    for keyword in structure_types:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for lighting keywords
    for keyword in lighting_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for furniture keywords
    for keyword in furniture_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for wall keywords
    for keyword in wall_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for garden keywords
    for keyword in garden_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for accessories keywords
    for keyword in accessories_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Check for color keywords
    for keyword in color_keywords:
        if keyword in text_lower:
            detected_colors.append(keyword)
    
    # Check for space character keywords
    for keyword in space_character_keywords:
        if keyword in text_lower:
            detected_objects.append(keyword)
    
    # Add basic object detection for common items
    basic_objects = {
        "island": ["island", "kitchen island", "◊ê◊ô", "◊ê◊ô ◊û◊ò◊ë◊ó"],
        "bed": ["bed", "bedframe", "headboard", "◊û◊ô◊ò◊î", "◊û◊ô◊ò◊ï◊™"],
        "sofa": ["sofa", "couch", "settee", "◊°◊§◊î", "◊°◊§◊ï◊™"],
        "table": ["table", "dining table", "coffee table", "◊©◊ï◊ú◊ó◊ü", "◊©◊ï◊ú◊ó◊†◊ï◊™"],
        "chair": ["chair", "dining chair", "armchair", "◊õ◊ô◊°◊ê", "◊õ◊ô◊°◊ê◊ï◊™"],
        "stove": ["stove", "cooktop", "range", "◊õ◊ô◊®◊ô◊ô◊ù", "◊™◊†◊ï◊®", "◊™◊†◊ï◊®◊ô◊ù"],
        "sink": ["sink", "faucet", "◊õ◊ô◊ï◊®", "◊õ◊ô◊ï◊®◊ô◊ù"],
        "lamp": ["lamp", "lighting", "chandelier", "◊û◊†◊ï◊®◊î", "◊û◊†◊ï◊®◊ï◊™", "◊™◊ê◊ï◊®◊î"],
        "cabinet": ["cabinet", "cupboard", "storage", "◊ê◊®◊ï◊ü", "◊ê◊®◊ï◊†◊ï◊™", "◊ê◊®◊ï◊†◊ï◊™ ◊û◊ò◊ë◊ó"],
        "mirror": ["mirror", "reflection", "◊û◊®◊ê◊î", "◊û◊®◊ê◊ï◊™"],
        "rug": ["rug", "carpet", "mat", "◊©◊ò◊ô◊ó", "◊©◊ò◊ô◊ó◊ô◊ù"],
        "curtain": ["curtain", "drape", "blind", "◊ï◊ô◊ú◊ï◊ü", "◊ï◊ô◊ú◊ï◊†◊ï◊™"],
        "window": ["window", "windows", "◊ó◊ú◊ï◊ü", "◊ó◊ú◊ï◊†◊ï◊™", "◊ó◊ú◊ï◊†◊ï◊™ ◊í◊ì◊ï◊ú◊ô◊ù"],
        "door": ["door", "doors", "◊ì◊ú◊™", "◊ì◊ú◊™◊ï◊™"],
        "marble": ["marble", "◊©◊ô◊©", "◊ê◊ë◊ü ◊©◊ô◊©"],
        "faucet": ["faucet", "tap", "◊ë◊®◊ñ", "◊ë◊®◊ñ◊ô◊ù", "◊ë◊®◊ñ ◊û◊ï◊ì◊®◊†◊ô"]
    }
    
    for obj, keywords in basic_objects.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_objects.append(obj)
    
    # Color detection (Hebrew + English) - Enhanced
    colors = {
        "red": ["red", "crimson", "maroon", "◊ê◊ì◊ï◊ù", "◊ê◊ì◊ï◊û◊î", "◊ê◊ì◊ï◊û◊ô◊ù"],
        "blue": ["blue", "navy", "azure", "teal", "◊õ◊ó◊ï◊ú", "◊õ◊ó◊ï◊ú◊î", "◊õ◊ó◊ï◊ú◊ô◊ù"],
        "green": ["green", "emerald", "forest", "mint", "◊ô◊®◊ï◊ß", "◊ô◊®◊ï◊ß◊î", "◊ô◊®◊ï◊ß◊ô◊ù"],
        "yellow": ["yellow", "gold", "amber", "◊¶◊î◊ï◊ë", "◊¶◊î◊ï◊ë◊î", "◊¶◊î◊ï◊ë◊ô◊ù"],
        "white": ["white", "ivory", "cream", "◊ú◊ë◊ü", "◊ú◊ë◊†◊î", "◊ú◊ë◊†◊ô◊ù", "◊ú◊ë◊†◊ï◊™"],
        "black": ["black", "charcoal", "ebony", "◊©◊ó◊ï◊®", "◊©◊ó◊ï◊®◊î", "◊©◊ó◊ï◊®◊ô◊ù", "◊©◊ó◊ï◊®◊ï◊™"],
        "gray": ["gray", "grey", "silver", "◊ê◊§◊ï◊®", "◊ê◊§◊ï◊®◊î", "◊ê◊§◊ï◊®◊ô◊ù", "◊ê◊§◊ï◊®◊ï◊™"],
        "brown": ["brown", "tan", "beige", "◊ó◊ï◊ù", "◊ó◊ï◊û◊î", "◊ó◊ï◊û◊ô◊ù", "◊ó◊ï◊û◊ï◊™"],
        "pink": ["pink", "rose", "coral", "◊ï◊®◊ï◊ì", "◊ï◊®◊ï◊ì◊î", "◊ï◊®◊ï◊ì◊ô◊ù", "◊ï◊®◊ï◊ì◊ï◊™"],
        "purple": ["purple", "violet", "lavender", "◊°◊í◊ï◊ú", "◊°◊í◊ï◊ú◊î", "◊°◊í◊ï◊ú◊ô◊ù", "◊°◊í◊ï◊ú◊ï◊™"],
        "orange": ["orange", "peach", "apricot", "◊õ◊™◊ï◊ù", "◊õ◊™◊ï◊û◊î", "◊õ◊™◊ï◊û◊ô◊ù", "◊õ◊™◊ï◊û◊ï◊™"],
        "warm colors": ["warm colors", "◊¶◊ë◊¢◊ô◊ù ◊ó◊û◊ô◊ù", "◊¶◊ë◊¢◊ô◊ù ◊ó◊û◊ô◊ù"]
    }
    
    detected_colors = []
    for color_name, keywords in colors.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_colors.append(color_name)
    
    # Return comprehensive results
    return {
        "location": detected_location,
        "style": detected_styles,
        "required_objects": detected_objects,
        "required_colors": detected_colors
    }

def generate_ai_proposal(selected_images, requirements=None):
    """Generate AI proposal for selected images"""
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        # Prepare image descriptions
        image_descriptions = []
        for img in selected_images:
            desc = f"Image: {img['name']} - Objects: {', '.join(img['objects'])} - Colors: {len(img['colors'])} colors - Folder: {img['folder']}"
            image_descriptions.append(desc)
        
        # Create prompt for proposal generation
        prompt = f"""You are an expert interior designer creating a professional proposal for a client. 
        
        Based on the following selected images and requirements, create a comprehensive design proposal:
        
        Selected Images:
        {chr(10).join(image_descriptions)}
        
        Client Requirements:
        {requirements if requirements else "No specific requirements provided"}
        
        Please create a professional proposal that includes:
        1. Executive Summary
        2. Design Concept & Vision
        3. Space Analysis
        4. Recommended Design Elements
        5. Color Palette & Materials
        6. Implementation Timeline
        7. Budget Considerations
        8. Next Steps
        
        Make it professional, detailed, and actionable. Use Hebrew and English as appropriate."""
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a professional interior designer with expertise in creating detailed design proposals."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"AI proposal generation failed: {e}")
        return f"""# Design Proposal

## Executive Summary
Based on the selected images, we present a comprehensive design proposal that combines functionality with aesthetic appeal.

## Selected Images Analysis
{chr(10).join([f"- {img['name']}: {', '.join(img['objects'])}" for img in selected_images])}

## Design Concept
The proposed design focuses on creating a cohesive and functional space that meets your requirements.

## Implementation
1. Review selected images
2. Finalize design elements
3. Begin implementation
4. Quality assurance

## Next Steps
Please review this proposal and let us know if you'd like to proceed with any modifications."""

@app.post("/parse_requirements")
async def parse_requirements(file: UploadFile = File(...)):
    """Parse storyboard/PDF to extract design requirements"""
    try:
        print(f"üìÑ Starting PDF parsing for file: {file.filename}")
        
        # Add overall timeout for the entire parsing process
        async def parse_with_timeout():
            return await _parse_requirements_internal(file)
        
        try:
            result = await asyncio.wait_for(parse_with_timeout(), timeout=120.0)  # 2 minute total timeout
            return result
        except asyncio.TimeoutError:
            print("‚ùå PDF parsing timed out after 2 minutes")
            return JSONResponse(
                status_code=408,
                content={"error": "PDF parsing timed out. Please try with a smaller file or simpler text."}
            )
    except Exception as e:
        print(f"‚ùå PDF parsing failed: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"PDF parsing failed: {str(e)}"}
        )

async def _parse_requirements_internal(file: UploadFile):
    """Internal PDF parsing logic"""
    try:
        # Read file with timeout
        print("üìñ Reading file content...")
        content = await asyncio.wait_for(file.read(), timeout=30.0)
        print(f"‚úÖ File read successfully, size: {len(content)} bytes")

        # Determine file type and extract text
        if file.filename.lower().endswith('.pdf'):
            print("üìÑ Extracting text from PDF...")
            text = extract_text_from_pdf(content)
            print(f"‚úÖ PDF text extracted, length: {len(text)} characters")
        else:
            # Assume text file
            print("üìù Decoding text file...")
            text = content.decode(errors="ignore")
            print(f"‚úÖ Text decoded, length: {len(text)} characters")

        if not text.strip():
            print("‚ùå No text extracted from file")
            return JSONResponse(
                status_code=400,
                content={"error": "Could not extract text from the uploaded file"}
            )

        # Extract requirements using OpenAI API with timeout
        print("ü§ñ Starting AI requirements extraction...")
        try:
            parsed = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(None, extract_requirements_from_text, text),
                timeout=60.0
            )
            print(f"‚úÖ AI parsing completed: {parsed}")
        except asyncio.TimeoutError:
            print("‚ùå AI parsing timed out")
            return JSONResponse(
                status_code=408,
                content={"error": "AI parsing timed out. Please try with a smaller file or simpler text."}
            )
        
        # Auto-search for matching images if requirements were found
        print("üîç Starting auto-search for matching images...")
        search_results = []
        if parsed and (parsed.get("location") or parsed.get("style") or parsed.get("required_objects") or parsed.get("required_colors")):
            print("‚úÖ Requirements found, proceeding with auto-search")
            try:
                # Create search query from requirements
                search_parts = []
                if parsed and parsed.get("location"):
                    search_parts.append(parsed["location"])
                if parsed and parsed.get("style"):
                    search_parts.extend(parsed["style"])
                if parsed and parsed.get("required_objects"):
                    search_parts.extend(parsed["required_objects"][:3])  # Limit to first 3 objects

                search_query = " ".join(search_parts)
                print(f"üîç Auto-search query: {search_query}")

                # Perform search if we have images indexed
                if image_index and len(image_index) > 0:
                    print(f"üìä Found {len(image_index)} indexed images, performing search...")
                    # Create search request
                    search_request = {
                        "query": search_query,
                        "required_objects": parsed.get("required_objects", []) if parsed else [],
                        "required_colors": parsed.get("required_colors", []) if parsed else [],
                        "top_k": 6
                    }

                    print(f"üîç Auto-search objects: {parsed.get('required_objects', []) if parsed else []}")
                    print(f"üîç Auto-search colors: {parsed.get('required_colors', []) if parsed else []}")

                    # Call search function with timeout
                    try:
                        print("üîç Executing search...")
                        search_results = await asyncio.wait_for(
                            asyncio.get_event_loop().run_in_executor(None, search_images_internal, search_request),
                            timeout=30.0
                        )
                        print(f"‚úÖ Auto-search found {len(search_results)} results")
                    except asyncio.TimeoutError:
                        print("‚ùå Auto-search timed out")
                        search_results = []
                else:
                    print("‚ùå No images indexed for auto-search")
                    
            except Exception as e:
                print(f"‚ùå Auto-search failed: {e}")
                search_results = []
        else:
            print("‚ùå No requirements found for auto-search")
        
        print("üì§ Preparing response...")
        response_data = {
            "status": "success",
            "filename": file.filename,
            "requirements": parsed,
            "auto_search_results": search_results,
            "search_query": search_query if 'search_query' in locals() else None
        }
        print(f"‚úÖ Response prepared: {len(search_results)} auto-search results")
        
        return JSONResponse(content=response_data)
        
    except Exception as e:
        print(f"‚ùå Parse requirements error: {e}")
        import traceback
        print(f"üìã Full traceback: {traceback.format_exc()}")
        return JSONResponse(
            status_code=400,
            content={"error": f"Failed to parse file: {str(e)}"}
        )

# ---------------------------
# Additional Utility Endpoints
# ---------------------------
@app.get("/stats")
def get_stats():
    """Get indexing statistics"""
    if not image_index:
        return {"message": "No images indexed yet"}
    
    all_objects = []
    all_colors = []
    for data in image_index.values():
        all_objects.extend(data['objects'])
        all_colors.extend(data['colors'])
    
    object_counts = Counter(all_objects)
    color_counts = Counter([str(c) for c in all_colors])
    
    return {
        "total_images": len(image_index),
        "total_objects_detected": len(object_counts),
        "most_common_objects": dict(object_counts.most_common(10)),
        "most_common_colors": dict(color_counts.most_common(10))
    }

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "device": device,
        "authenticated": drive_service is not None,
        "images_indexed": len(image_index)
    }

# ---------------------------
# Health Check
# ---------------------------
@app.get("/image/{file_id}")
async def get_image(file_id: str):
    """Serve image from Google Drive with improved error handling"""
    if not drive_service:
        raise HTTPException(status_code=401, detail="Not authenticated with Google Drive")
    
    try:
        print(f"üñºÔ∏è Loading image: {file_id}")
        
        # Simple, direct approach with better error handling
        try:
            # Get file metadata with error handling
            try:
                file_metadata = drive_service.files().get(fileId=file_id).execute()
                print(f"‚úÖ File metadata retrieved: {file_metadata.get('name', 'Unknown')}")
            except Exception as meta_error:
                print(f"‚ùå Failed to get file metadata: {meta_error}")
                # Return placeholder for metadata errors
                placeholder = create_placeholder_image()
                return StreamingResponse(
                    io.BytesIO(placeholder),
                    media_type="image/png",
                    headers={"Content-Disposition": f"inline; filename=metadata_error.png"}
                )
            
            # Download file content with retry logic
            file_content = None
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"üîÑ Download attempt {attempt + 1}/{max_retries} for {file_id}")
                    request = drive_service.files().get_media(fileId=file_id)
                    file_content = request.execute()
                    print(f"‚úÖ Image downloaded successfully, size: {len(file_content)} bytes")
                    break
                except Exception as download_error:
                    print(f"‚ùå Download attempt {attempt + 1} failed: {download_error}")
                    if attempt == max_retries - 1:
                        print(f"‚ùå All {max_retries} download attempts failed for {file_id}")
                        # Return placeholder for download errors
                        placeholder = create_placeholder_image()
                        return StreamingResponse(
                            io.BytesIO(placeholder),
                            media_type="image/png",
                            headers={"Content-Disposition": f"inline; filename=download_error.png"}
                        )
                    else:
                        import time
                        time.sleep(1)  # Wait 1 second before retry
            
            # Determine content type
            mime_type = file_metadata.get('mimeType', 'image/jpeg')
            
            return StreamingResponse(
                io.BytesIO(file_content),
                media_type=mime_type,
                headers={"Content-Disposition": f"inline; filename={file_metadata.get('name', 'image')}"}
            )
            
        except Exception as e:
            print(f"‚ùå Unexpected error in image serving: {e}")
            # Return placeholder image for any error
            try:
                placeholder = create_placeholder_image()
                return StreamingResponse(
                    io.BytesIO(placeholder),
                    media_type="image/png",
                    headers={"Content-Disposition": f"inline; filename=error_placeholder.png"}
                )
            except:
                return JSONResponse(status_code=500, content={"error": "Image unavailable"})
                
    except Exception as e:
        print(f"‚ùå Unexpected error loading image: {e}")
        return JSONResponse(status_code=500, content={"error": "Internal server error"})

@app.post("/export_pdf")
async def export_pdf(request: dict):
    """Export selected images to PDF"""
    if not drive_service:
        raise HTTPException(status_code=401, detail="Not authenticated with Google Drive")
    
    try:
        file_ids = request.get('file_ids', [])
        file_names = request.get('file_names', [])
        
        if not file_ids:
            raise HTTPException(status_code=400, detail="No file IDs provided")
        
        # Create PDF in memory
        pdf_buffer = io.BytesIO()
        doc = SimpleDocTemplate(pdf_buffer, pagesize=A4)
        story = []
        styles = getSampleStyleSheet()
        
        # Add company logo
        try:
            logo_data = create_company_logo()
            logo_buffer = io.BytesIO(logo_data)
            logo = RLImage(logo_buffer, width=3*inch, height=0.9*inch)
            story.append(logo)
            story.append(Spacer(1, 20))
        except Exception as e:
            print(f"Error adding logo to PDF: {e}")
            # Add text title as fallback
            title = Paragraph("Idan Locations", styles['Title'])
            story.append(title)
            story.append(Spacer(1, 12))
        
        # Add Hebrew introduction
        hebrew_intro = """
        ◊î◊¶◊¢◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù
        
        ◊™◊ß◊¶◊ô◊® ◊û◊†◊î◊ú◊ô◊ù:
        ◊©◊û◊ó◊ô◊ù ◊ú◊î◊¶◊ô◊í ◊ë◊§◊†◊ô◊õ◊ù ◊û◊ë◊ó◊® ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊û◊ô◊ï◊ó◊ì ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù. ◊î◊î◊¶◊¢◊î ◊†◊ë◊†◊™◊î ◊û◊™◊ï◊ö ◊û◊ò◊®◊î ◊ú◊ê◊§◊©◊® ◊ú◊õ◊ù ◊û◊ë◊ò ◊û◊û◊ï◊ß◊ì, ◊†◊í◊ô◊© ◊ï◊ë◊®◊ï◊® ◊¢◊ú ◊û◊ß◊ï◊û◊ï◊™ ◊§◊ï◊ò◊†◊¶◊ô◊ê◊ú◊ô◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù.
        
        ◊ó◊ñ◊ï◊ü ◊ï◊ß◊ï◊†◊°◊§◊ò:
        ◊ë÷æIdan Locations ◊ê◊†◊ï ◊û◊™◊û◊ó◊ô◊ù ◊ë◊î◊™◊ê◊û◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊û◊ì◊ï◊ô◊ß◊ô◊ù ◊ú◊î◊§◊ß◊ï◊™ ◊ß◊ï◊ú◊†◊ï◊¢, ◊ò◊ú◊ï◊ï◊ô◊ñ◊ô◊î ◊ï◊§◊®◊°◊ï◊û◊ï◊™. ◊î◊ó◊ñ◊ï◊ü ◊©◊ú◊†◊ï ◊î◊ï◊ê ◊ú◊ó◊ë◊® ◊ë◊ô◊ü ◊¶◊®◊õ◊ô ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù ◊ú◊ë◊ô◊ü ◊î◊û◊®◊ó◊ë ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊û◊ë◊ó◊ô◊†◊î ◊ï◊ô◊ñ◊ï◊ê◊ú◊ô◊™, ◊ú◊ï◊í◊ô◊°◊ò◊ô◊™ ◊ï◊î◊§◊ß◊™◊ô◊™.
        
        ◊°◊ß◊ô◊®◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù:
        ◊î◊™◊û◊ï◊†◊ï◊™ ◊©◊ú◊§◊†◊ô◊õ◊ù ◊û◊¶◊ô◊í◊ï◊™ ◊ê◊™◊®◊ô◊ù ◊®◊ú◊ï◊ï◊†◊ò◊ô◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊ß◊§◊ô◊ì◊î, ◊û◊™◊ï◊ö ◊©◊ô◊ß◊ï◊ú◊ô◊ù ◊©◊ú ◊†◊®◊ê◊ï◊™, ◊†◊í◊ô◊©◊ï◊™ ◊ï◊™◊†◊ê◊ô ◊î◊§◊ß◊î. ◊õ◊ú ◊û◊ô◊ß◊ï◊ù ◊†◊ï◊™◊ü ◊û◊¢◊†◊î ◊ú◊ê◊ï◊§◊ô ◊î◊°◊¶◊†◊ï◊™ ◊ï◊î◊ê◊ï◊ï◊ô◊®◊î ◊©◊ë◊®◊¶◊ï◊†◊õ◊ù ◊ú◊ô◊¶◊ï◊®.
        
        ◊ô◊™◊®◊ï◊†◊ï◊™ ◊û◊®◊õ◊ñ◊ô◊ô◊ù:
        ‚Ä¢ ◊û◊í◊ï◊ï◊ü ◊°◊í◊†◊ï◊†◊ï◊™ ◊ï◊†◊ï◊§◊ô◊ù ◊ë◊û◊ß◊ï◊ù ◊ê◊ó◊ì
        ‚Ä¢ ◊†◊í◊ô◊©◊ï◊™ ◊í◊ë◊ï◊î◊î ◊ú◊¶◊ï◊ï◊™◊ô ◊¶◊ô◊ú◊ï◊ù ◊ï◊î◊§◊ß◊î
        ‚Ä¢ ◊ê◊§◊©◊®◊ï◊ô◊ï◊™ ◊í◊û◊ô◊©◊ï◊™ ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î
        ‚Ä¢ ◊†◊ô◊°◊ô◊ï◊ü ◊ï◊ú◊ô◊ï◊ï◊ô ◊û◊ß◊¶◊ï◊¢◊ô ◊ú◊ê◊ï◊®◊ö ◊õ◊ú ◊î◊™◊î◊ú◊ô◊ö
        
        ◊©◊ú◊ë◊ô◊ù ◊î◊ë◊ê◊ô◊ù:
        ◊†◊©◊û◊ó ◊ú◊ß◊ô◊ô◊ù ◊§◊í◊ô◊©◊™ ◊î◊û◊©◊ö ◊ú◊ë◊ó◊ô◊®◊™ ◊î◊ú◊ï◊ß◊ô◊ô◊©◊ü ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊ï◊ú◊î◊™◊ó◊ú◊™ ◊™◊î◊ú◊ô◊ö ◊î◊™◊ô◊ê◊ï◊ù ◊ë◊©◊ò◊ó.
        
        ◊™◊ï◊ì◊î ◊¢◊ú ◊©◊ô◊™◊ï◊£ ◊î◊§◊¢◊ï◊ú◊î,
        Idan Locations
        """
        
        # Create custom style for Hebrew text
        hebrew_style = ParagraphStyle(
            'HebrewStyle',
            parent=styles['Normal'],
            fontSize=11,
            spaceAfter=15,
            alignment=TA_RIGHT,  # Right-to-left for Hebrew
            fontName='Helvetica'
        )
        
        intro_paragraph = Paragraph(hebrew_intro, hebrew_style)
        story.append(intro_paragraph)
        story.append(Spacer(1, 20))
        
        # Add section title
        section_title = Paragraph("◊™◊û◊ï◊†◊ï◊™ ◊†◊ë◊ó◊®◊ï◊™", styles['Heading1'])
        story.append(section_title)
        story.append(Spacer(1, 12))
        
        for i, (file_id, file_name) in enumerate(zip(file_ids, file_names)):
            try:
                # Get image from Drive or uploaded images
                if file_id.startswith('uploaded_'):
                    # Handle uploaded image
                    if file_id not in image_index or not image_index[file_id].get("is_uploaded"):
                        raise Exception(f"Uploaded image {file_id} not found")
                    image_content = io.BytesIO(image_index[file_id]["image_data"])
                else:
                    # Handle Google Drive image
                    if not drive_service:
                        raise Exception("Not authenticated with Google Drive")
                    request_drive = drive_service.files().get_media(fileId=file_id)
                    image_content = io.BytesIO()
                    downloader = request_drive.execute()
                    image_content.write(downloader)
                    image_content.seek(0)
                
                # Create PIL image to get dimensions
                pil_image = Image.open(image_content)
                image_content.seek(0)
                
                # Calculate size for PDF (max width 6 inches, maintain aspect ratio)
                max_width = 6 * inch
                width, height = pil_image.size
                aspect_ratio = height / width
                
                if width > max_width:
                    display_width = max_width
                    display_height = display_width * aspect_ratio
                else:
                    display_width = width
                    display_height = height
                
                # Add image name
                story.append(Paragraph(f"<b>{file_name}</b>", styles['Normal']))
                story.append(Spacer(1, 6))
                
                # Add image
                rl_image = RLImage(image_content, width=display_width, height=display_height)
                story.append(rl_image)
                story.append(Spacer(1, 12))
                
            except Exception as e:
                # Add error message for failed images
                story.append(Paragraph(f"<b>{file_name}</b> - Error loading image: {str(e)}", styles['Normal']))
                story.append(Spacer(1, 12))
        
        # Build PDF
        doc.build(story)
        pdf_buffer.seek(0)
        
        return StreamingResponse(
            io.BytesIO(pdf_buffer.getvalue()),
            media_type="application/pdf",
            headers={"Content-Disposition": "attachment; filename=Idan_Locations_Proposal.pdf"}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"PDF generation failed: {str(e)}")

@app.post("/export_word")
async def export_word(request: dict):
    """Export selected images to Word document with AI proposal"""
    try:
        file_ids = request.get("file_ids", [])
        file_names = request.get("file_names", [])
        include_proposal = request.get("include_proposal", True)
        
        if not file_ids:
            return JSONResponse(
                status_code=400,
                content={"error": "No images selected for export"}
            )
        
        # Get selected images data for AI proposal
        selected_images = []
        for file_id, name in zip(file_ids, file_names):
            if file_id in image_index:
                img_data = image_index[file_id]
                selected_images.append({
                    'name': name,
                    'objects': img_data['objects'],
                    'colors': img_data['colors'],
                    'folder': img_data.get('folder', 'Root')
                })
        
        # Generate AI proposal if requested
        proposal_text = ""
        if include_proposal and selected_images:
            proposal_text = generate_ai_proposal(selected_images)
        
        # Create Word document
        doc = Document()
        
        # Add company logo
        try:
            logo_data = create_company_logo()
            logo_buffer = io.BytesIO(logo_data)
            logo_paragraph = doc.add_paragraph()
            logo_run = logo_paragraph.runs[0] if logo_paragraph.runs else logo_paragraph.add_run()
            logo_paragraph.alignment = 1  # Center alignment
            # Note: Adding images to Word requires more complex handling
            # For now, we'll add the company name as a styled heading
        except Exception as e:
            print(f"Error adding logo to Word: {e}")
        
        # Add company title
        title = doc.add_heading('Idan Locations', 0)
        title.alignment = 1  # Center alignment
        
        # Add Hebrew introduction
        hebrew_intro = """
        ◊î◊¶◊¢◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù
        
        ◊™◊ß◊¶◊ô◊® ◊û◊†◊î◊ú◊ô◊ù:
        ◊©◊û◊ó◊ô◊ù ◊ú◊î◊¶◊ô◊í ◊ë◊§◊†◊ô◊õ◊ù ◊û◊ë◊ó◊® ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊û◊ô◊ï◊ó◊ì ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù. ◊î◊î◊¶◊¢◊î ◊†◊ë◊†◊™◊î ◊û◊™◊ï◊ö ◊û◊ò◊®◊î ◊ú◊ê◊§◊©◊® ◊ú◊õ◊ù ◊û◊ë◊ò ◊û◊û◊ï◊ß◊ì, ◊†◊í◊ô◊© ◊ï◊ë◊®◊ï◊® ◊¢◊ú ◊û◊ß◊ï◊û◊ï◊™ ◊§◊ï◊ò◊†◊¶◊ô◊ê◊ú◊ô◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù.
        
        ◊ó◊ñ◊ï◊ü ◊ï◊ß◊ï◊†◊°◊§◊ò:
        ◊ë÷æIdan Locations ◊ê◊†◊ï ◊û◊™◊û◊ó◊ô◊ù ◊ë◊î◊™◊ê◊û◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊û◊ì◊ï◊ô◊ß◊ô◊ù ◊ú◊î◊§◊ß◊ï◊™ ◊ß◊ï◊ú◊†◊ï◊¢, ◊ò◊ú◊ï◊ï◊ô◊ñ◊ô◊î ◊ï◊§◊®◊°◊ï◊û◊ï◊™. ◊î◊ó◊ñ◊ï◊ü ◊©◊ú◊†◊ï ◊î◊ï◊ê ◊ú◊ó◊ë◊® ◊ë◊ô◊ü ◊¶◊®◊õ◊ô ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù ◊ú◊ë◊ô◊ü ◊î◊û◊®◊ó◊ë ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊û◊ë◊ó◊ô◊†◊î ◊ï◊ô◊ñ◊ï◊ê◊ú◊ô◊™, ◊ú◊ï◊í◊ô◊°◊ò◊ô◊™ ◊ï◊î◊§◊ß◊™◊ô◊™.
        
        ◊°◊ß◊ô◊®◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù:
        ◊î◊™◊û◊ï◊†◊ï◊™ ◊©◊ú◊§◊†◊ô◊õ◊ù ◊û◊¶◊ô◊í◊ï◊™ ◊ê◊™◊®◊ô◊ù ◊®◊ú◊ï◊ï◊†◊ò◊ô◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊ß◊§◊ô◊ì◊î, ◊û◊™◊ï◊ö ◊©◊ô◊ß◊ï◊ú◊ô◊ù ◊©◊ú ◊†◊®◊ê◊ï◊™, ◊†◊í◊ô◊©◊ï◊™ ◊ï◊™◊†◊ê◊ô ◊î◊§◊ß◊î. ◊õ◊ú ◊û◊ô◊ß◊ï◊ù ◊†◊ï◊™◊ü ◊û◊¢◊†◊î ◊ú◊ê◊ï◊§◊ô ◊î◊°◊¶◊†◊ï◊™ ◊ï◊î◊ê◊ï◊ï◊ô◊®◊î ◊©◊ë◊®◊¶◊ï◊†◊õ◊ù ◊ú◊ô◊¶◊ï◊®.
        
        ◊ô◊™◊®◊ï◊†◊ï◊™ ◊û◊®◊õ◊ñ◊ô◊ô◊ù:
        ‚Ä¢ ◊û◊í◊ï◊ï◊ü ◊°◊í◊†◊ï◊†◊ï◊™ ◊ï◊†◊ï◊§◊ô◊ù ◊ë◊û◊ß◊ï◊ù ◊ê◊ó◊ì
        ‚Ä¢ ◊†◊í◊ô◊©◊ï◊™ ◊í◊ë◊ï◊î◊î ◊ú◊¶◊ï◊ï◊™◊ô ◊¶◊ô◊ú◊ï◊ù ◊ï◊î◊§◊ß◊î
        ‚Ä¢ ◊ê◊§◊©◊®◊ï◊ô◊ï◊™ ◊í◊û◊ô◊©◊ï◊™ ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î
        ‚Ä¢ ◊†◊ô◊°◊ô◊ï◊ü ◊ï◊ú◊ô◊ï◊ï◊ô ◊û◊ß◊¶◊ï◊¢◊ô ◊ú◊ê◊ï◊®◊ö ◊õ◊ú ◊î◊™◊î◊ú◊ô◊ö
        
        ◊©◊ú◊ë◊ô◊ù ◊î◊ë◊ê◊ô◊ù:
        ◊†◊©◊û◊ó ◊ú◊ß◊ô◊ô◊ù ◊§◊í◊ô◊©◊™ ◊î◊û◊©◊ö ◊ú◊ë◊ó◊ô◊®◊™ ◊î◊ú◊ï◊ß◊ô◊ô◊©◊ü ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊ï◊ú◊î◊™◊ó◊ú◊™ ◊™◊î◊ú◊ô◊ö ◊î◊™◊ô◊ê◊ï◊ù ◊ë◊©◊ò◊ó.
        
        ◊™◊ï◊ì◊î ◊¢◊ú ◊©◊ô◊™◊ï◊£ ◊î◊§◊¢◊ï◊ú◊î,
        Idan Locations
        """
        
        intro_paragraph = doc.add_paragraph(hebrew_intro)
        intro_paragraph.alignment = 2  # Right alignment for Hebrew
        doc.add_paragraph()  # Add spacing
        
        # Add subtitle
        subtitle = doc.add_heading('◊™◊û◊ï◊†◊ï◊™ ◊†◊ë◊ó◊®◊ï◊™', level=1)
        
        # Add AI proposal if available
        if proposal_text:
            doc.add_heading('◊î◊¶◊¢◊î ◊û◊ë◊ï◊°◊°◊™ AI', level=1)
            
            # Split proposal into paragraphs
            proposal_paragraphs = proposal_text.split('\n\n')
            for para in proposal_paragraphs:
                if para.strip():
                    doc.add_paragraph(para.strip())
        
        # Add images section
        doc.add_heading('◊™◊û◊ï◊†◊ï◊™ ◊†◊ë◊ó◊®◊ï◊™', level=1)
        
        # Add images
        for file_id, name in zip(file_ids, file_names):
            try:
                # Get image content
                if file_id.startswith("uploaded_"):
                    # Handle uploaded images
                    image_path = f"uploaded_images/{file_id}.jpg"
                    if os.path.exists(image_path):
                        doc.add_paragraph(f"Image: {name}")
                        doc.add_picture(image_path, width=Inches(4))
                else:
                    # Handle Google Drive images
                    if drive_service:
                        request_drive = drive_service.files().get_media(fileId=file_id)
                        image_content = request_drive.execute()
                        
                        # Save temporary image
                        temp_path = f"temp_{file_id}.jpg"
                        with open(temp_path, 'wb') as f:
                            f.write(image_content)
                        
                        doc.add_paragraph(f"Image: {name}")
                        doc.add_picture(temp_path, width=Inches(4))
                        
                        # Clean up temp file
                        os.remove(temp_path)
            except Exception as e:
                print(f"Error adding image {name}: {e}")
                continue
        
        # Save to buffer
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        
        return StreamingResponse(
            io.BytesIO(buffer.read()),
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={"Content-Disposition": "attachment; filename=idan_locations_proposal.docx"}
        )
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"Word export failed: {str(e)}"}
        )

@app.post("/export_ppt")
async def export_ppt(request: dict):
    """Export selected images to PowerPoint presentation with AI proposal"""
    try:
        file_ids = request.get("file_ids", [])
        file_names = request.get("file_names", [])
        include_proposal = request.get("include_proposal", True)
        
        if not file_ids:
            return JSONResponse(
                status_code=400,
                content={"error": "No images selected for export"}
            )
        
        # Get selected images data for AI proposal
        selected_images = []
        for file_id, name in zip(file_ids, file_names):
            if file_id in image_index:
                img_data = image_index[file_id]
                selected_images.append({
                    'name': name,
                    'objects': img_data['objects'],
                    'colors': img_data['colors'],
                    'folder': img_data.get('folder', 'Root')
                })
        
        # Generate AI proposal if requested
        proposal_text = ""
        if include_proposal and selected_images:
            proposal_text = generate_ai_proposal(selected_images)
        
        # Create PowerPoint presentation
        prs = Presentation()
        
        # Title slide with company branding and logo
        title_slide_layout = prs.slide_layouts[0]
        slide = prs.slides.add_slide(title_slide_layout)
        title = slide.shapes.title
        subtitle = slide.placeholders[1]
        
        # Add company logo to title slide
        try:
            logo_data = create_company_logo()
            logo_buffer = io.BytesIO(logo_data)
            # Save logo temporarily
            temp_logo_path = "temp_logo.png"
            with open(temp_logo_path, 'wb') as f:
                f.write(logo_data)
            
            # Add logo to slide (positioned at top)
            slide.shapes.add_picture(temp_logo_path, Inches(1), Inches(0.5), Inches(8), Inches(2.4))
            
            # Clean up temp file
            os.remove(temp_logo_path)
        except Exception as e:
            print(f"Error adding logo to PowerPoint: {e}")
        
        title.text = "◊î◊¶◊¢◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù"
        subtitle.text = "Idan Locations"
        
        # Add executive summary slide
        summary_slide_layout = prs.slide_layouts[1]
        summary_slide = prs.slides.add_slide(summary_slide_layout)
        summary_title = summary_slide.shapes.title
        summary_content = summary_slide.placeholders[1]
        
        summary_title.text = "◊™◊ß◊¶◊ô◊® ◊û◊†◊î◊ú◊ô◊ù"
        hebrew_summary = """◊©◊û◊ó◊ô◊ù ◊ú◊î◊¶◊ô◊í ◊ë◊§◊†◊ô◊õ◊ù ◊û◊ë◊ó◊® ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊û◊ô◊ï◊ó◊ì ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù. ◊î◊î◊¶◊¢◊î ◊†◊ë◊†◊™◊î ◊û◊™◊ï◊ö ◊û◊ò◊®◊î ◊ú◊ê◊§◊©◊® ◊ú◊õ◊ù ◊û◊ë◊ò ◊û◊û◊ï◊ß◊ì, ◊†◊í◊ô◊© ◊ï◊ë◊®◊ï◊® ◊¢◊ú ◊û◊ß◊ï◊û◊ï◊™ ◊§◊ï◊ò◊†◊¶◊ô◊ê◊ú◊ô◊ô◊ù ◊ú◊¶◊ô◊ú◊ï◊û◊ô◊ù.

◊ó◊ñ◊ï◊ü ◊ï◊ß◊ï◊†◊°◊§◊ò:
◊ë÷æIdan Locations ◊ê◊†◊ï ◊û◊™◊û◊ó◊ô◊ù ◊ë◊î◊™◊ê◊û◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊û◊ì◊ï◊ô◊ß◊ô◊ù ◊ú◊î◊§◊ß◊ï◊™ ◊ß◊ï◊ú◊†◊ï◊¢, ◊ò◊ú◊ï◊ï◊ô◊ñ◊ô◊î ◊ï◊§◊®◊°◊ï◊û◊ï◊™. ◊î◊ó◊ñ◊ï◊ü ◊©◊ú◊†◊ï ◊î◊ï◊ê ◊ú◊ó◊ë◊® ◊ë◊ô◊ü ◊¶◊®◊õ◊ô ◊î◊î◊§◊ß◊î ◊©◊ú◊õ◊ù ◊ú◊ë◊ô◊ü ◊î◊û◊®◊ó◊ë ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊û◊ë◊ó◊ô◊†◊î ◊ï◊ô◊ñ◊ï◊ê◊ú◊ô◊™, ◊ú◊ï◊í◊ô◊°◊ò◊ô◊™ ◊ï◊î◊§◊ß◊™◊ô◊™."""
        
        summary_content.text = hebrew_summary
        
        # Add locations overview slide
        overview_slide_layout = prs.slide_layouts[1]
        overview_slide = prs.slides.add_slide(overview_slide_layout)
        overview_title = overview_slide.shapes.title
        overview_content = overview_slide.placeholders[1]
        
        overview_title.text = "◊°◊ß◊ô◊®◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù ◊ï◊ô◊™◊®◊ï◊†◊ï◊™"
        hebrew_overview = """◊°◊ß◊ô◊®◊™ ◊ú◊ï◊ß◊ô◊ô◊©◊†◊ô◊ù:
◊î◊™◊û◊ï◊†◊ï◊™ ◊©◊ú◊§◊†◊ô◊õ◊ù ◊û◊¶◊ô◊í◊ï◊™ ◊ê◊™◊®◊ô◊ù ◊®◊ú◊ï◊ï◊†◊ò◊ô◊ô◊ù ◊©◊†◊ë◊ó◊®◊ï ◊ë◊ß◊§◊ô◊ì◊î, ◊û◊™◊ï◊ö ◊©◊ô◊ß◊ï◊ú◊ô◊ù ◊©◊ú ◊†◊®◊ê◊ï◊™, ◊†◊í◊ô◊©◊ï◊™ ◊ï◊™◊†◊ê◊ô ◊î◊§◊ß◊î.

◊ô◊™◊®◊ï◊†◊ï◊™ ◊û◊®◊õ◊ñ◊ô◊ô◊ù:
‚Ä¢ ◊û◊í◊ï◊ï◊ü ◊°◊í◊†◊ï◊†◊ï◊™ ◊ï◊†◊ï◊§◊ô◊ù ◊ë◊û◊ß◊ï◊ù ◊ê◊ó◊ì
‚Ä¢ ◊†◊í◊ô◊©◊ï◊™ ◊í◊ë◊ï◊î◊î ◊ú◊¶◊ï◊ï◊™◊ô ◊¶◊ô◊ú◊ï◊ù ◊ï◊î◊§◊ß◊î
‚Ä¢ ◊ê◊§◊©◊®◊ï◊ô◊ï◊™ ◊í◊û◊ô◊©◊ï◊™ ◊ë◊î◊™◊ê◊ù ◊ú◊ì◊®◊ô◊©◊ï◊™ ◊î◊î◊§◊ß◊î
‚Ä¢ ◊†◊ô◊°◊ô◊ï◊ü ◊ï◊ú◊ô◊ï◊ï◊ô ◊û◊ß◊¶◊ï◊¢◊ô ◊ú◊ê◊ï◊®◊ö ◊õ◊ú ◊î◊™◊î◊ú◊ô◊ö

◊©◊ú◊ë◊ô◊ù ◊î◊ë◊ê◊ô◊ù:
◊†◊©◊û◊ó ◊ú◊ß◊ô◊ô◊ù ◊§◊í◊ô◊©◊™ ◊î◊û◊©◊ö ◊ú◊ë◊ó◊ô◊®◊™ ◊î◊ú◊ï◊ß◊ô◊ô◊©◊ü ◊î◊û◊™◊ê◊ô◊ù ◊ë◊ô◊ï◊™◊® ◊ï◊ú◊î◊™◊ó◊ú◊™ ◊™◊î◊ú◊ô◊ö ◊î◊™◊ô◊ê◊ï◊ù ◊ë◊©◊ò◊ó."""
        
        overview_content.text = hebrew_overview
        
        # AI proposal slides if available
        if proposal_text:
            proposal_slide_layout = prs.slide_layouts[1]
            slide = prs.slides.add_slide(proposal_slide_layout)
            title = slide.shapes.title
            content = slide.placeholders[1]
            
            title.text = "◊î◊¶◊¢◊î ◊û◊ë◊ï◊°◊°◊™ AI"
            
            # Split proposal into slides
            proposal_paragraphs = proposal_text.split('\n\n')
            current_slide_text = ""
            
            for para in proposal_paragraphs:
                if para.strip():
                    if len(current_slide_text + para) > 1000:  # Limit text per slide
                        content.text = current_slide_text
                        slide = prs.slides.add_slide(proposal_slide_layout)
                        title = slide.shapes.title
                        content = slide.placeholders[1]
                        title.text = "Design Proposal (Continued)"
                        current_slide_text = para.strip() + "\n\n"
                    else:
                        current_slide_text += para.strip() + "\n\n"
            
            if current_slide_text:
                content.text = current_slide_text
        
        # Images slides
        for file_id, name in zip(file_ids, file_names):
            try:
                # Create slide for each image
                img_slide_layout = prs.slide_layouts[5]  # Blank layout
                slide = prs.slides.add_slide(img_slide_layout)
                
                # Add title
                title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.5), Inches(9), Inches(1))
                title_frame = title_box.text_frame
                title_frame.text = name
                
                # Get image content
                if file_id.startswith("uploaded_"):
                    # Handle uploaded images
                    image_path = f"uploaded_images/{file_id}.jpg"
                    if os.path.exists(image_path):
                        slide.shapes.add_picture(image_path, Inches(1), Inches(1.5), Inches(8), Inches(6))
                else:
                    # Handle Google Drive images
                    if drive_service:
                        request_drive = drive_service.files().get_media(fileId=file_id)
                        image_content = request_drive.execute()
                        
                        # Save temporary image
                        temp_path = f"temp_{file_id}.jpg"
                        with open(temp_path, 'wb') as f:
                            f.write(image_content)
                        
                        slide.shapes.add_picture(temp_path, Inches(1), Inches(1.5), Inches(8), Inches(6))
                        
                        # Clean up temp file
                        os.remove(temp_path)
            except Exception as e:
                print(f"Error adding image {name}: {e}")
                continue
        
        # Save to buffer
        buffer = io.BytesIO()
        prs.save(buffer)
        buffer.seek(0)
        
        return StreamingResponse(
            io.BytesIO(buffer.read()),
            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
            headers={"Content-Disposition": "attachment; filename=idan_locations_proposal.pptx"}
        )
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"PowerPoint export failed: {str(e)}"}
        )

@app.post("/upload_images")
async def upload_images(images: List[UploadFile] = File(...)):
    """Upload and index multiple images"""
    global image_index
    
    if not images:
        raise HTTPException(status_code=400, detail="No images provided")
    
    uploaded_images = []
    
    for image_file in images:
        try:
            # Read image file
            image_content = await image_file.read()
            image_bytes = io.BytesIO(image_content)
            
            # Open and process image
            img = Image.open(image_bytes).convert("RGB")
            
            # Generate unique ID for uploaded image
            import uuid
            file_id = f"uploaded_{uuid.uuid4().hex}"
            
            # CLIP embedding
            inputs = clip_processor(images=img, return_tensors="pt")
            inputs = {k: v.to(device) for k, v in inputs.items()}
            with torch.no_grad():
                image_features = clip_model.get_image_features(**inputs)
                embedding = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # Extract dominant colors
            colors = extract_dominant_colors(img)
            
            # YOLO object detection
            objects = detect_objects_yolo(img)
            
            # Store in index
            image_index[file_id] = {
                "name": image_file.filename,
                "embedding": embedding.cpu(),
                "objects": objects,
                "colors": colors,
                "folder": "Uploaded Images",
                "is_uploaded": True,
                "image_data": image_content  # Store image data for serving
            }
            
            # Create preview URL
            preview_url = f"/uploaded_image/{file_id}"
            
            uploaded_images.append({
                "file_id": file_id,
                "name": image_file.filename,
                "objects": objects,
                "colors": colors,
                "preview_url": preview_url
            })
            
            print(f"Uploaded and indexed: {image_file.filename} - Objects: {objects} - Colors: {colors}")
            
        except Exception as e:
            print(f"Failed to process uploaded image {image_file.filename}: {e}")
            continue
    
    return JSONResponse(content={
        "count": len(uploaded_images),
        "uploaded_images": uploaded_images,
        "message": f"Successfully uploaded and indexed {len(uploaded_images)} image(s)"
    })

@app.get("/uploaded_image/{file_id}")
async def get_uploaded_image(file_id: str):
    """Serve uploaded image"""
    if file_id not in image_index:
        raise HTTPException(status_code=404, detail="Image not found")
    
    image_data = image_index[file_id]
    if not image_data.get("is_uploaded"):
        raise HTTPException(status_code=404, detail="Image not found")
    
    image_content = image_data["image_data"]
    
    return StreamingResponse(
        io.BytesIO(image_content),
        media_type="image/jpeg",
        headers={"Content-Disposition": f"inline; filename={image_data['name']}"}
    )

@app.post("/analyze_storyboard")
async def analyze_storyboard(storyboard: UploadFile = File(...)):
    """Analyze storyboard image and find similar images"""
    global image_index
    
    if not image_index:
        raise HTTPException(status_code=400, detail="No images indexed. Please index your images first.")
    
    try:
        # Read and process storyboard image
        image_content = await storyboard.read()
        image_bytes = io.BytesIO(image_content)
        img = Image.open(image_bytes).convert("RGB")
        
        # Analyze storyboard
        storyboard_analysis = analyze_storyboard_image(img)
        
        # Find similar images
        similar_images = []
        for file_id, data in image_index.items():
            # Calculate semantic similarity
            semantic_sim = (storyboard_analysis['embedding'] @ data['embedding'].T).item()
            
            # Calculate object similarity
            storyboard_objects = set(storyboard_analysis['objects'])
            image_objects = set(data['objects'])
            if storyboard_objects or image_objects:
                object_sim = len(storyboard_objects & image_objects) / len(storyboard_objects | image_objects)
            else:
                object_sim = 1.0
            
            # Calculate color similarity
            color_sim = color_match_score(data['colors'], storyboard_analysis['colors'])
            
            # Combined similarity score
            similarity_score = calculate_combined_score(semantic_sim, object_sim, color_sim)
            
            similar_images.append({
                'file_id': file_id,
                'name': data['name'],
                'folder': data.get('folder', 'Root'),
                'similarity_score': similarity_score,
                'object_match': object_sim,
                'color_match': color_sim,
                'objects': data['objects'],
                'colors': data['colors']
            })
        
        # Sort by similarity score
        similar_images.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # Return top 10 similar images
        return JSONResponse(content={
            'analysis': {
                'objects': storyboard_analysis['objects'],
                'colors': storyboard_analysis['colors'],
                'suggested_rooms': storyboard_analysis['suggested_rooms']
            },
            'similar_images': similar_images[:10],
            'message': f"Found {len(similar_images)} similar images"
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Storyboard analysis failed: {str(e)}")

@app.get("/")
def root():
    return {
        "message": "Google Drive AI Search v3 with YOLOv8 running",
        "endpoints": {
            "auth": "/auth - Authenticate with Google Drive",
            "auth_status": "/auth/status - Check authentication status",
            "auth_disconnect": "/auth/disconnect - Disconnect from Google Drive",
            "index": "/index - Index all Drive images",
            "search": "/search - Search images with AI",
            "parse": "/parse_requirements - Parse storyboard/PDF",
            "upload": "/upload_images - Upload and index images",
            "storyboard": "/analyze_storyboard - Analyze storyboard and find similar images",
            "stats": "/stats - Get indexing statistics",
            "image": "/image/{file_id} - Get image from Drive",
            "uploaded": "/uploaded_image/{file_id} - Get uploaded image",
            "export": "/export_pdf - Export images to PDF",
            "health": "/health - Health check"
        }
    }
